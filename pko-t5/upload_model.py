#!/usr/bin/env python3
"""
PKO-T5 ê¸°ë°˜ SLM ëª¨ë¸ì„ Hugging Face Hubì— ì—…ë¡œë“œ
"""

import os
from huggingface_hub import HfApi, create_repo
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

def upload_model_to_hf():
    # ì„¤ì •
    MODEL_PATH = "/Volumes/Data/slm_model/checkpoint-2300"  # ìµœì‹  ì²´í¬í¬ì¸íŠ¸
    HF_USERNAME = "BBoDDoGood"  # ì—¬ê¸°ì— í—ˆê¹…í˜ì´ìŠ¤ ì‚¬ìš©ìëª… ì…ë ¥
    MODEL_NAME = "SLM_pko-t5"  # ì›í•˜ëŠ” ëª¨ë¸ëª…
    REPO_ID = f"{HF_USERNAME}/{MODEL_NAME}"
    
    print("ğŸš€ PKO-T5 SLM ëª¨ë¸ ì—…ë¡œë“œ ì‹œì‘")
    print(f"ëª¨ë¸ ê²½ë¡œ: {MODEL_PATH}")
    print(f"ì—…ë¡œë“œ ëŒ€ìƒ: {REPO_ID}")
    
    # API ì´ˆê¸°í™”
    api = HfApi()
    
    try:
        # 1. ë ˆí¬ì§€í† ë¦¬ ìƒì„±
        print("\n1ï¸âƒ£ Hugging Face ë ˆí¬ì§€í† ë¦¬ ìƒì„± ì¤‘...")
        create_repo(
            repo_id=REPO_ID,
            repo_type="model",
            exist_ok=True,
            private=False  # ê³µê°œ ëª¨ë¸ë¡œ ì„¤ì • (ì›í•˜ë©´ Trueë¡œ ë³€ê²½)
        )
        print(f"âœ… ë ˆí¬ì§€í† ë¦¬ ìƒì„± ì™„ë£Œ: https://huggingface.co/{REPO_ID}")
        
        # 2. ëª¨ë¸ íŒŒì¼ ì—…ë¡œë“œ
        print("\n2ï¸âƒ£ ëª¨ë¸ íŒŒì¼ ì—…ë¡œë“œ ì¤‘...")
        
        # ì—…ë¡œë“œí•  íŒŒì¼ë“¤
        files_to_upload = [
            "model.safetensors",      # ë©”ì¸ ëª¨ë¸ (1.0GB)
            "config.json",            # ëª¨ë¸ ì„¤ì •
            "generation_config.json", # ìƒì„± ì„¤ì •
            "tokenizer.json",         # í† í¬ë‚˜ì´ì € (4.2MB)
            "tokenizer_config.json",  # í† í¬ë‚˜ì´ì € ì„¤ì •
            "special_tokens_map.json" # íŠ¹ìˆ˜ í† í° ë§¤í•‘
        ]
        
        for file_name in files_to_upload:
            file_path = os.path.join(MODEL_PATH, file_name)
            if os.path.exists(file_path):
                print(f"  ğŸ“¤ {file_name} ì—…ë¡œë“œ ì¤‘...")
                api.upload_file(
                    path_or_fileobj=file_path,
                    path_in_repo=file_name,
                    repo_id=REPO_ID,
                    repo_type="model"
                )
                print(f"  âœ… {file_name} ì—…ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"  âš ï¸  {file_name} íŒŒì¼ ì—†ìŒ")
        
        # 3. README.md ìƒì„± ë° ì—…ë¡œë“œ
        print("\n3ï¸âƒ£ README.md ìƒì„± ì¤‘...")
        readme_content = f"""---
language:
- ko
license: mit
tags:
- korean
- t5
- crowd-monitoring
- slm
- pko-t5
datasets:
- custom
pipeline_tag: text2text-generation
---

# PKO-T5 SLM: êµ°ì¤‘ ëª¨ë‹ˆí„°ë§ ì „ë¬¸ ëª¨ë¸

ì´ ëª¨ë¸ì€ PKO-T5ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ°ì¤‘ ëª¨ë‹ˆí„°ë§ ë° ìƒí™© ë¶„ì„ì„ ìœ„í•´ íŠ¹ë³„íˆ í›ˆë ¨ëœ Small Language Model(SLM)ì…ë‹ˆë‹¤.

## ëª¨ë¸ ì •ë³´

- **Base Model**: `paust/pko-t5-base`
- **Language**: Korean (í•œêµ­ì–´)
- **Task**: Text-to-Text Generation
- **Domain**: êµ°ì¤‘ ëª¨ë‹ˆí„°ë§, ìƒí™© ë¶„ì„, ì•ˆì „ ê´€ë¦¬

## ì§€ì› ë„ë©”ì¸

1. **êµ°ì¤‘ ë°€ì§‘ ë° ì²´ë¥˜ ê°ì§€**
2. **ì“°ëŸ¬ì§ ë° ì¥ê¸° ì •ì§€ ê°ì§€**  
3. **ì—°ê¸° ë° í™”ì—¼ ê°ì§€**
4. **ì‘ì—…ì ì•ˆì „ì¥ë¹„ ë¯¸ì°©ìš© ê°ì§€**
5. **íì‡„ì‹œê°„ ë¬´ë‹¨ ì¶œì… ê°ì§€**
6. **ì•ˆì „ì¥ë¹„ ë¯¸ì°©ìš© ê°ì§€**
7. **ì˜¨ë„ ê¸°ë°˜ ì¾Œì ë„ ë° í­ì—¼ ì˜ˆë³´ ì•ˆë‚´**
8. **íˆíŠ¸ë§µ ê¸°ë°˜ ì²´ë¥˜ ìœ„í—˜êµ¬ê°„ ë¶„ì„**
9. **ì¤„ ì„œê¸° ë° ëŒ€ê¸°ì—´ ì •ë ¬ ìƒíƒœ ê°ì§€**
10. **ì´ìƒ ì´ë™ íŒ¨í„´ ê°ì§€**

## ì‚¬ìš© ë°©ë²•

```python
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# ëª¨ë¸ ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained("{REPO_ID}")
model = AutoModelForSeq2SeqLM.from_pretrained("{REPO_ID}")

# ì…ë ¥ ì˜ˆì‹œ
input_text = "êµ°ì¤‘ ë°€ì§‘ ë° ì²´ë¥˜ ê°ì§€, ì˜¤í›„ 2ì‹œ 30ë¶„ì— ì§€í•˜ì²  2í˜¸ì„  ê°•ë‚¨ì—­ì—ì„œ 50ëª…ì´ 5ë¶„ê°„ ì²´ë¥˜í–ˆìŠµë‹ˆë‹¤, ê¸°ì¤€: 30ëª…"

# í† í°í™” ë° ìƒì„±
inputs = tokenizer(input_text, return_tensors="pt", max_length=256, truncation=True)
outputs = model.generate(**inputs, max_length=256, num_beams=4, early_stopping=True)
result = tokenizer.decode(outputs[0], skip_special_tokens=True)

print(result)
```

## í›ˆë ¨ ë°ì´í„°

- **ì´ ë°ì´í„° ìˆ˜**: 100,000ê°œ (ê° ë„ë©”ì¸ 10,000ê°œ)
- **í›ˆë ¨ ìŠ¤í…**: 19,999 steps (99.995% ì™„ë£Œ)
- **ì†ì‹¤ê°’**: 0.33 (eval_loss)
- **í›ˆë ¨ ì‹œê°„**: ì•½ 1.5ì‹œê°„

## ë¼ì´ì„ ìŠ¤

MIT License

## ì¸ìš©

```bibtex
@model{{pko-t5-slm-crowd-monitoring,
  title={{PKO-T5 SLM: Korean Crowd Monitoring Specialized Model}},
  author={{SLM Development Team}},
  year={{2025}},
  url={{https://huggingface.co/{REPO_ID}}}
}}
```
"""
        
        # README.md ì„ì‹œ íŒŒì¼ ìƒì„±
        readme_path = "/tmp/README.md"
        with open(readme_path, "w", encoding="utf-8") as f:
            f.write(readme_content)
        
        # README.md ì—…ë¡œë“œ
        api.upload_file(
            path_or_fileobj=readme_path,
            path_in_repo="README.md",
            repo_id=REPO_ID,
            repo_type="model"
        )
        print("âœ… README.md ì—…ë¡œë“œ ì™„ë£Œ")
        
        print("\nğŸ‰ ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ!")
        print(f"ğŸ“± ëª¨ë¸ í˜ì´ì§€: https://huggingface.co/{REPO_ID}")
        print(f"ğŸ’» ì‚¬ìš©ë²•: transformers.AutoModel.from_pretrained('{REPO_ID}')")
        
    except Exception as e:
        print(f"âŒ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False
    
    return True

if __name__ == "__main__":
    upload_model_to_hf()