import random
import csv
import json
import os
import re
from typing import List, Dict, Tuple, Set
from collections import Counter

class Domain3SmokeFlameDetectionGenerator:
    """
    ë„ë©”ì¸3 ì—°ê¸° ë° í™”ì—¼ ê°ì§€ ë°ì´í„°ì…‹ ìƒì„±ê¸°
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ë‹¤ì–‘í•œ ì¥ì†Œì˜ ì—°ê¸°/í™”ì—¼ ê°ì§€ ìƒí™© ë°ì´í„° ìƒì„±
    - ê°ì§€ ì‹œê°„ê³¼ ê¸°ì¤€ ì‹œê°„ ë¹„êµ ë¶„ì„
    - ìœ„í—˜ë„ë³„ ì ì ˆí•œ ì¡°ì¹˜ ë°©ì•ˆ ì œì‹œ
    - ë‹¨ì¼/ë³µí•© ê°ì§€ ìœ í˜• ì²˜ë¦¬
    - ìì—°ìŠ¤ëŸ¬ìš´ 2~3ë¬¸ì¥ Output ìƒì„±
    - 1000ê°œ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ìƒì„±
    """
    
    def __init__(self):
        """ìƒì„±ê¸° ì´ˆê¸°í™” - ëª¨ë“  ì„¤ì •ê°’ê³¼ íŒ¨í„´ ì •ì˜"""
        
        # ê°ì§€ ì‹œê°„ ë²”ìœ„ (ì´ˆ)
        self.detection_time_ranges = {
            "ë‹¨ê¸°": {"min": 2, "max": 5, "weight": 40},      # 2-5ì´ˆ, 40%
            "ì¤‘ê¸°": {"min": 6, "max": 10, "weight": 35},     # 6-10ì´ˆ, 35%
            "ì¥ê¸°": {"min": 11, "max": 20, "weight": 20},    # 11-20ì´ˆ, 20%
            "ì´ˆì¥ê¸°": {"min": 21, "max": 60, "weight": 5}    # 21-60ì´ˆ, 5%
        }
        
        # ê¸°ì¤€ ì‹œê°„ ë²”ìœ„ (ì´ˆ)
        self.baseline_time_ranges = {
            "ì—„ê²©": {"min": 1, "max": 3, "weight": 30},      # 1-3ì´ˆ, 30%
            "ë³´í†µ": {"min": 4, "max": 7, "weight": 45},      # 4-7ì´ˆ, 45%
            "ê´€ëŒ€": {"min": 8, "max": 15, "weight": 25}      # 8-15ì´ˆ, 25%
        }
        
        # ê°ì§€ ìœ í˜•
        self.detection_types = {
            "ì—°ê¸°": {"weight": 35, "expressions": ["ì—°ê¸°", "ì—°ê¸°ê°€", "ì—°ê¸°Â·ë¶ˆê½ƒ", "ì—°ê¸°Â·í™”ì—¼"]},
            "í™”ì—¼": {"weight": 25, "expressions": ["í™”ì—¼", "í™”ì—¼ì´", "í™”ì—¼Â·ì—°ê¸°", "í™”ì—¼Â·ë¶ˆê½ƒ"]},
            "ë¶ˆê½ƒ": {"weight": 20, "expressions": ["ë¶ˆê½ƒ", "ë¶ˆê½ƒì´", "ë¶ˆê½ƒÂ·ì—°ê¸°"]},
            "ë³µí•©": {"weight": 20, "expressions": ["ì—°ê¸°Â·í™”ì—¼ ë™ì‹œ", "ë¶ˆê½ƒÂ·ì—°ê¸° ë™ì‹œ", "í™”ì—¼Â·ì—°ê¸° ë™ì‹œ", "ì—°ê¸°ì™€ ë¶ˆê½ƒ", "í™”ì—¼ê³¼ ì—°ê¸°"]}
        }
        
        # ì¥ì†Œëª… - ì—°ê¸°/í™”ì—¼ì´ ê°ì§€ë  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì¥ì†Œ
        self.locations = [
            # ì‚°ì—…ì‹œì„¤
            "ì œì² ì†Œ", "í™”í•™ê³µì¥", "ìë™ì°¨ê³µì¥", "ì¡°ì„ ì†Œ", "ì„ìœ í™”í•™ê³µì¥", "ê³µì¥", "ì •ìœ ê³µì¥",
            "ë¬¼ë¥˜ì„¼í„°", "ë¬¼ë¥˜ì°½ê³ ", "ì œì¡°ê³µì¥",
            
            # ìƒì—…ì‹œì„¤
            "ì‡¼í•‘ëª°", "ë°±í™”ì ", "ëŒ€í˜•ë§ˆíŠ¸", "ë§ˆíŠ¸", "í¸ì˜ì ", "ìƒê°€", "ì¹´í˜", "ë ˆìŠ¤í† ë‘",
            "ë¯¸ìš©ì‹¤", "ë…¸ë˜ë°©", "ì„¸íƒì†Œ", "ë“œë¼ì´ë¸ŒìŠ¤ë£¨",
            
            # ì˜ë£Œì‹œì„¤
            "ë³‘ì›", "ì¢…í•©ë³‘ì›", "ë™ë¬¼ë³‘ì›", "ì¹˜ê³¼", "ì•½êµ­", "ìš”ì–‘ì›", "ì–‘ë¡œì›",
            
            # êµìœ¡ì‹œì„¤
            "í•™êµ", "ëŒ€í•™êµ", "ëŒ€í•™", "ì—°êµ¬ì†Œ",
            
            # êµí†µì‹œì„¤
            "ì§€í•˜ì² ì—­", "ê³µí•­", "í„°ë¯¸ë„", "ê³ ì†ë„ë¡œ íœ´ê²Œì†Œ",
            
            # ìˆ™ë°•/ì—¬ê°€ì‹œì„¤
            "í˜¸í…”", "íœì…˜", "ëª¨í…”", "ë¦¬ì¡°íŠ¸", "ì°œì§ˆë°©", "ì‚¬ìš°ë‚˜", "ìŠ¤í¬ì¸ ì„¼í„°",
            "ì²´ìœ¡ê´€", "ìˆ˜ì˜ì¥", "ì˜í™”ê´€", "ê³µì—°ì¥", "ë†€ì´ê³µì›",
            
            # ì£¼ê±°ì‹œì„¤
            "ì•„íŒŒíŠ¸", "ë¹Œë”©",
            
            # ê¸°íƒ€ì‹œì„¤
            "ì£¼ìœ ì†Œ", "ë†ì¥", "ì›¨ë”©í™€", "ë„ì„œê´€", "ê³µì›"
        ]
        
        # ì¥ì†Œë³„ ì „ìš© êµ¬ì—­ëª… ë§¤í•‘
        self.location_specific_areas = {
            # ì‚°ì—…ì‹œì„¤
            "ì œì² ì†Œ": ["3í˜¸ë™ ìš©ê´‘ë¡œ ì•", "ìš©ê´‘ë¡œ", "ë³´ì¼ëŸ¬ì‹¤"],
            "í™”í•™ê³µì¥": ["ë°˜ì‘ê¸° 1í˜¸", "í™”í•™ì €ì¥ê³ "],
            "ìë™ì°¨ê³µì¥": ["ë„ì¥ë¼ì¸", "ë„ì¥ë¶€ìŠ¤"],
            "ê³µì¥": ["2ë¼ì¸ ë³´ì¼ëŸ¬ì‹¤", "ìš©ì ‘ì‘ì—…ì¥", "ë‚¨ë™ìª½ ìš©ì ‘ì¥", "í¬ì¥ë¼ì¸", "ê¸°ê³„ì‹¤", 
                   "ì°½ê³ ", "ë‚¨ë™ìª½ ì ì¬ì¥", "ì „ê¸°ì‹¤", "ëƒ‰ë™ì°½ê³ "],
            "ì •ìœ ê³µì¥": ["ì €ì¥íƒ±í¬"],
            "ì œì¡°ê³µì¥": ["í’ˆì§ˆê²€ì‚¬ì‹¤"],
            "ë¬¼ë¥˜ì„¼í„°": ["Aë™ ì°½ê³ ", "ë‚¨ë™ìª½ ì ì¬ì¥"],
            "ë¬¼ë¥˜ì°½ê³ ": ["ì ì¬êµ¬ì—­"],
            
            # ìƒì—…ì‹œì„¤
            "ì‡¼í•‘ëª°": ["ì§€í•˜1ì¸µ í‘¸ë“œì½”íŠ¸", "ì˜ë¥˜ë§¤ì¥"],
            "ë°±í™”ì ": ["ì‹í’ˆë§¤ì¥", "í™”ì¥í’ˆ ë§¤ì¥"],
            "ë§ˆíŠ¸": ["ê³„ì‚°ëŒ€", "ëƒ‰ë™ì‹í’ˆ ì½”ë„ˆ"],
            "ìƒê°€": ["Bë™ ì¹´í˜ í…Œë¼ìŠ¤"],
            "ì¹´í˜": ["í…Œë¼ìŠ¤", "í™€", "ì•¼ì™¸ì„"],
            "ë ˆìŠ¤í† ë‘": ["ì£¼ë°© ì¡°ë¦¬ëŒ€"],
            "ë¯¸ìš©ì‹¤": ["íŒŒë§ˆì¡´"],
            "ë…¸ë˜ë°©": ["3í˜¸ì‹¤", "ê°œì¸ì‹¤"],
            
            # ì˜ë£Œì‹œì„¤
            "ë³‘ì›": ["Aë™ ì‘ê¸‰ì‹¤ ì…êµ¬", "ì‘ê¸‰ì‹¤", "ì¤‘í™˜ìì‹¤"],
            "ì¢…í•©ë³‘ì›": ["ì‚°ë¶€ì¸ê³¼"],
            
            # êµìœ¡ì‹œì„¤
            "í•™êµ": ["ë¶ê´€ ê³¼í•™ì‹¤", "í™”í•™ì‹¤í—˜ì‹¤", "ê¸‰ì‹ì‹¤", "ìš´ë™ì¥"],
            "ëŒ€í•™êµ": ["ì‹¤ìŠµì‹¤", "ê°•ì˜ì‹¤"],
            "ëŒ€í•™": ["ë„ì„œê´€ ì—´ëŒì‹¤"],
            "ì—°êµ¬ì†Œ": ["ì‹¤í—˜ì‹¤ Bë™"],
            
            # êµí†µì‹œì„¤
            "ì§€í•˜ì² ì—­": ["2í˜¸ì„  ìŠ¹ê°•ì¥", "í™˜ìŠ¹í†µë¡œ"],
            "ê³µí•­": ["êµ­ì œì„  ëŒ€ê¸°ì‹¤", "ë©´ì„¸ì ", "ìˆ˜í•˜ë¬¼ ì²˜ë¦¬ì¥"],
            "ê³ ì†ë„ë¡œ íœ´ê²Œì†Œ": ["ìŒì‹ì "],
            
            # ìˆ™ë°•/ì—¬ê°€ì‹œì„¤
            "í˜¸í…”": ["1ì¸µ ë¡œë¹„", "ì—°íšŒì¥", "ë ˆìŠ¤í† ë‘ ì£¼ë°©"],
            "íœì…˜": ["Aë™ ë³µë„", "ë°”ë² íì¥", "ê°ì‹¤", "ê°ì‹¤ ë°œì½”ë‹ˆ"],
            "ëª¨í…”": ["ë³µë„", "ì—˜ë¦¬ë² ì´í„°í™€"],
            "ë¦¬ì¡°íŠ¸": ["ìŠ¤íŒŒ ì‚¬ìš°ë‚˜ì‹¤"],
            "ì°œì§ˆë°©": ["íœ´ê²Œì‹¤", "ì‚¬ìš°ë‚˜ì‹¤"],
            "ìŠ¤í¬ì¸ ì„¼í„°": ["ìˆ˜ì˜ì¥ íƒˆì˜ì‹¤"],
            "ì²´ìœ¡ê´€": ["ë™ê´€ ë†êµ¬ì½”íŠ¸", "ë†êµ¬ì½”íŠ¸"],
            "ê³µì—°ì¥": ["ë¬´ëŒ€ ë’¤í¸", "ê°ì„", "ë¬´ëŒ€ ì¡°ëª…ì‹¤"],
            "ë†€ì´ê³µì›": ["íšŒì „ëª©ë§ˆ"],
            
            # ì£¼ê±°ì‹œì„¤
            "ì•„íŒŒíŠ¸": ["7ë™ 13ì¸µ ë³µë„", "ì˜¥ìƒ", "ì§€í•˜ ì£¼ì°¨ì¥", "ì˜¥ìƒ ê¸°ê³„ì‹¤", "ê´€ë¦¬ì‚¬ë¬´ì†Œ"],
            "ë¹Œë”©": ["ì§€í•˜ì£¼ì°¨ì¥"],
            
            # ê¸°íƒ€ì‹œì„¤
            "ë†ì¥": ["ë¶ìª½ ì°½ê³ ", "ì¶•ì‚¬"],
            "ì›¨ë”©í™€": ["ì‹ ë¶€ëŒ€ê¸°ì‹¤"],
            "ë„ì„œê´€": ["ì—´ëŒì‹¤"],
            "í„°ë¯¸ë„": ["ëŒ€í•©ì‹¤", "ìŠ¹ì°¨ì¥"]
        }
        
        # ìƒí™© ìœ í˜•ë³„ íŒ¨í„´
        self.situation_patterns = {
            "ê·¹ë„ìœ„í—˜": {  # ê¸°ì¤€ì˜ 3ë°° ì´ìƒ ì´ˆê³¼
                "weight": 15,
                "exceed_ratio": (3.0, 10.0),
                "keywords": ["ê·¹ë„ë¡œ ìœ„í—˜í•œ", "ê·¹ë„ìœ„í—˜", "í­ë°œ ìœ„í—˜"]
            },
            "ìœ„í—˜ìƒí™©": {  # ê¸°ì¤€ì˜ 1.5ë°°~3ë°° ì´ˆê³¼
                "weight": 35,
                "exceed_ratio": (1.5, 3.0),
                "keywords": ["ìœ„í—˜ ìˆ˜ì¤€", "ìœ„í—˜ìƒí™©", "ìœ„í—˜ ìƒí™©"]
            },
            "ì´ˆê³¼ìƒí™©": {  # ê¸°ì¤€ì˜ 1.1ë°°~1.5ë°° ì´ˆê³¼
                "weight": 30,
                "exceed_ratio": (1.1, 1.5),
                "keywords": ["ì´ˆê³¼", "ë„˜ì–´", "ë„˜ê²¨"]
            },
            "ì •ìƒìƒí™©": {  # ê¸°ì¤€ ì´ë‚´
                "weight": 15,
                "exceed_ratio": (0.3, 0.9),
                "keywords": ["ì •ìƒ ë²”ìœ„", "ì•ˆì „í•œ", "ì •ìƒ"]
            },
            "ê¸°ì¤€ì—†ìŒ": {  # ê¸°ì¤€ ë¯¸ì„¤ì •
                "weight": 5,
                "exceed_ratio": None,
                "keywords": ["ê¸°ì¤€ ì—†ìŒ", "ë¯¸ì„¤ì •", "ì„¤ì •ë˜ì§€"]
            }
        }
        
        # ì‹œê°„ í‘œí˜„ í˜•ì‹
        self.time_formats = [
            "HH:MM",           # 08:12, 14:33
            "ìƒˆë²½ Hì‹œ Më¶„",     # ìƒˆë²½ 4ì‹œ 12ë¶„
            "ì˜¤ì „ Hì‹œ Më¶„",     # ì˜¤ì „ 11ì‹œ 16ë¶„
            "ì˜¤í›„ Hì‹œ Më¶„",     # ì˜¤í›„ 7ì‹œ 18ë¶„
            "ì €ë… Hì‹œ Më¶„",     # ì €ë… 9ì‹œ 15ë¶„
            "HHì‹œ MMë¶„"        # 16ì‹œ 29ë¶„
        ]
        
        # ì¡°ì¹˜ í‘œí˜„
        self.action_expressions = {
            "ê·¹ë„ìœ„í—˜": [
                "ì¦‰ì‹œ ì†Œë°©ëŒ€ íŠ¹ìˆ˜ ì¥ë¹„ ì¶œë™ì„ ìš”ì²­í•˜ê³ , ê³µì¥ ì „ì²´ ì‘ì—…ì ê¸´ê¸‰ ëŒ€í”¼ë¥¼ ì‹¤ì‹œí•˜ì„¸ìš”",
                "ì¦‰ì‹œ ì†Œë°©ëŒ€ íŠ¹ìˆ˜ ì§„ì••íŒ€ ì¶œë™ê³¼ ì£¼ë³€ ì£¼ë¯¼ ëŒ€í”¼ë¥¼ ìš”ì²­í•˜ì„¸ìš”",
                "ì†Œë°©ëŒ€ ê¸´ê¸‰ ì¶œë™ê³¼ ì „ê¸° ì „ë¬¸íŒ€ ì§€ì›ì„ ìš”ì²­í•˜ì„¸ìš”",
                "ì¦‰ì‹œ ê±´ë¬¼ ì „ì²´ ëŒ€í”¼ë¥¼ ê²€í† í•˜ì„¸ìš”",
            ],
            "ìœ„í—˜ìƒí™©": [
                "ì¦‰ì‹œ ìš´ì˜ì„ ì¤‘ë‹¨í•˜ê³  ì•ˆì „ ëŒ€í”¼ë¥¼ ì‹¤ì‹œí•˜ì‹­ì‹œì˜¤",
                "ì¦‰ì‹œ í•´ë‹¹ êµ¬ì—­ ìš´ì˜ì„ ì¤‘ë‹¨í•˜ê³  ì†Œë°©íŒ€ ì¶œë™ì„ ìš”ì²­í•˜ì„¸ìš”",
                "ì¦‰ì‹œ í˜„ì¥ í™•ì¸í•˜ê³  í•´ë‹¹ êµ¬ì—­ ì¶œì…ì„ ì œí•œí•˜ì‹­ì‹œì˜¤",
                "ì†Œë°©íŒ€ ì¶œë™ ìš”ì²­ í›„ ì¶”ê°€ ê°ì§€ ì‹œ ì „ì²´ ëŒ€í”¼ë¥¼ ê²€í† í•˜ì„¸ìš”",
                "ì¦‰ì‹œ ìš´ì˜ ì¤‘ë‹¨í•˜ê³  ê³ ê° ì•ˆì „ ëŒ€í”¼ë¥¼ ì‹¤ì‹œí•˜ì„¸ìš”"
            ],
            "ì´ˆê³¼ìƒí™©": [
                "í•´ë‹¹ êµ¬ì—­ ì ê²€ í›„ ì¶”ê°€ ê°ì§€ ì‹œ ìš´ì˜ ì¤‘ë‹¨ì„ ê³ ë ¤í•˜ì‹­ì‹œì˜¤",
                "ì¦‰ì‹œ í˜„ì¥ì„ ì ê²€í•˜ê³  ì•ˆì „ í™•ì¸ì„ ì‹¤ì‹œí•˜ì‹­ì‹œì˜¤",
                "í•´ë‹¹ êµ¬ì—­ ì´ìš©ì„ ì¼ì‹œ ì¤‘ë‹¨í•˜ê³  ì•ˆì „ ì ê²€ì„ ì‹¤ì‹œí•˜ì„¸ìš”",
                "ì¶”ê°€ ê°ì§€ë˜ë©´ í•´ë‹¹ êµ¬ì—­ ëŒ€í”¼ë¥¼ ê²€í† í•˜ì„¸ìš”",
                "ì¦‰ì‹œ ì ê²€í•˜ê³  ì¶”ê°€ ê°ì§€ ì‹œ ì†Œë°© ì•ˆì „ ì ê²€ì„ ìš”ì²­í•˜ì‹­ì‹œì˜¤"
            ],
            "ì •ìƒìƒí™©": [
                "ì¼ë°˜ ì ê²€ë§Œ í•˜ì‹œë©´ ë˜ë©°, ì¶”í›„ ê°ì§€ ì‹œ ì•ˆì „ ì ê²€ì„ ì‹¤ì‹œí•˜ì„¸ìš”",
                "ìƒíƒœë§Œ í™•ì¸í•˜ì‹œë©´ ë˜ë©°, ì´í›„ ê°ì§€ ì‹œ ì „ê¸° ì•ˆì „ ì ê²€ì„ ì‹¤ì‹œí•˜ì‹œê¸° ê¶Œí•©ë‹ˆë‹¤",
                "ì •ìƒ ì‘ì—…ì„ ì§€ì†í•˜ì‹­ì‹œì˜¤",
                "ì ê²€í•˜ê³  ì •ìƒ ì´ìš©ì— ì§€ì¥ì´ ì—†ë„ë¡ í•˜ì‹­ì‹œì˜¤",
                "í™•ì¸í•˜ê³ , í–¥í›„ ê°ì§€ ì‹œ ì¢…í•© ì•ˆì „ ì ê²€ì„ ì‹œí–‰í•˜ì‹­ì‹œì˜¤"
            ],
            "ê¸°ì¤€ì—†ìŒ": [
                "ì¦‰ì‹œ ìœ„í—˜ íŒë‹¨ì€ ì–´ë ¤ìš°ë‚˜ ì•ˆì „ ì ê²€ì„ ì‹¤ì‹œí•´ ì£¼ì„¸ìš”",
                "ê¸°ì¤€ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ì§€ë§Œ ì•ˆì „ì„ ìœ„í•´ ì ê²€í•˜ì‹­ì‹œì˜¤",
                "ì¦‰ì‹œ ìœ„í—˜í•˜ì§€ëŠ” ì•Šì§€ë§Œ ì‹œì„¤ ì ê²€ì„ ì‹¤ì‹œí•˜ì‹­ì‹œì˜¤",
                "ì„ê³„ê°’ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜ ì ê²€í•´ ì£¼ì„¸ìš”",
                "ê¸°ì¤€ ì—†ì´ ìƒí™© í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤"
            ]
        }
        
        # ê¸°ì¤€ í‘œí˜„
        self.baseline_expressions = [
            "ê¸°ì¤€", "ì„ê³„ê°’", "í—ˆìš©ì¹˜", "ì„ê³„ì¹˜", "í—ˆìš©ì¹˜", "ê¸°ì¤€ê°’"
        ]
        
        # ê¸°ì¤€ ìƒíƒœ í‘œí˜„
        self.baseline_status_expressions = [
            "ê¸°ì¤€ ì—†ìŒ", "í—ˆìš©ì¹˜ ì—†ìŒ", "ì„ê³„ê°’ ì—†ìŒ", "ê¸°ì¤€ ë¯¸ì„¤ì •", 
            "ë¯¸ì„¤ì •", "í—ˆìš©ì¹˜ ë¯¸ì„¤ì •", "ì„ê³„ê°’ ë¯¸ì„¤ì •", "ê¸°ì¤€ê°’ ë¯¸ì„¤ì •"
        ]
        
    def generate_detection_time(self) -> int:
        """ê°ì§€ ì‹œê°„ ìƒì„± (ì´ˆ)"""
        weights = [self.detection_time_ranges[key]["weight"] for key in self.detection_time_ranges.keys()]
        selected_range = random.choices(list(self.detection_time_ranges.keys()), weights=weights)[0]
        range_info = self.detection_time_ranges[selected_range]
        return random.randint(range_info["min"], range_info["max"])
    
    def generate_baseline_time(self, detection_time: int, situation_type: str) -> int:
        """ê¸°ì¤€ ì‹œê°„ ìƒì„± (ì´ˆ)"""
        if situation_type == "ê¸°ì¤€ì—†ìŒ":
            return None
        elif situation_type == "ê·¹ë„ìœ„í—˜":
            # ê¸°ì¤€ì˜ 3ë°°~10ë°° ì´ˆê³¼í•˜ë„ë¡ ê¸°ì¤€ ì„¤ì •
            exceed_min, exceed_max = self.situation_patterns["ê·¹ë„ìœ„í—˜"]["exceed_ratio"]
            baseline = int(detection_time / random.uniform(exceed_min, exceed_max))
            return max(1, baseline)
        elif situation_type == "ìœ„í—˜ìƒí™©":
            # ê¸°ì¤€ì˜ 1.5ë°°~3ë°° ì´ˆê³¼í•˜ë„ë¡ ê¸°ì¤€ ì„¤ì •
            exceed_min, exceed_max = self.situation_patterns["ìœ„í—˜ìƒí™©"]["exceed_ratio"]
            baseline = int(detection_time / random.uniform(exceed_min, exceed_max))
            return max(1, baseline)
        elif situation_type == "ì´ˆê³¼ìƒí™©":
            # ê¸°ì¤€ì˜ 1.1ë°°~1.5ë°° ì´ˆê³¼í•˜ë„ë¡ ê¸°ì¤€ ì„¤ì •
            exceed_min, exceed_max = self.situation_patterns["ì´ˆê³¼ìƒí™©"]["exceed_ratio"]
            baseline = int(detection_time / random.uniform(exceed_min, exceed_max))
            return max(1, baseline)
        else:  # ì •ìƒìƒí™©
            # ê¸°ì¤€ì˜ 30%~90% ìˆ˜ì¤€ìœ¼ë¡œ í˜„ì¬ ì‹œê°„ ì„¤ì •
            exceed_min, exceed_max = self.situation_patterns["ì •ìƒìƒí™©"]["exceed_ratio"]
            baseline = int(detection_time / random.uniform(exceed_min, exceed_max))
            return max(1, baseline)
    
    def select_situation_type(self) -> str:
        """ìƒí™© ìœ í˜• ì„ íƒ"""
        weights = [self.situation_patterns[key]["weight"] for key in self.situation_patterns.keys()]
        return random.choices(list(self.situation_patterns.keys()), weights=weights)[0]
    
    def generate_detection_type(self) -> str:
        """ê°ì§€ ìœ í˜• ìƒì„±"""
        weights = [self.detection_types[key]["weight"] for key in self.detection_types.keys()]
        selected_type = random.choices(list(self.detection_types.keys()), weights=weights)[0]
        return random.choice(self.detection_types[selected_type]["expressions"])
    
    def generate_time_expression(self) -> str:
        """ì‹œê°„ í‘œí˜„ ìƒì„±"""
        hour = random.randint(0, 23)
        minute = random.randint(0, 59)
        
        if hour < 6:
            return f"ìƒˆë²½ {hour}ì‹œ {minute}ë¶„"
        elif hour < 12:
            if random.random() < 0.3:
                return f"{hour:02d}:{minute:02d}"
            else:
                return f"ì˜¤ì „ {hour}ì‹œ {minute}ë¶„"
        elif hour < 18:
            if random.random() < 0.3:
                return f"{hour:02d}:{minute:02d}"
            else:
                return f"ì˜¤í›„ {hour-12 if hour > 12 else hour}ì‹œ {minute}ë¶„"
        else:
            if random.random() < 0.3:
                return f"{hour:02d}:{minute:02d}"
            else:
                return f"ì €ë… {hour-12}ì‹œ {minute}ë¶„"
    
    def generate_location_with_area(self) -> str:
        """ì¥ì†Œ + êµ¬ì—­ëª… ìƒì„±"""
        location = random.choice(self.locations)
        
        # 80% í™•ë¥ ë¡œ êµ¬ì—­ëª… ì¶”ê°€
        if random.random() < 0.8 and location in self.location_specific_areas:
            area = random.choice(self.location_specific_areas[location])
            return f"{location} {area}"
        else:
            return location
    
    def generate_baseline_expression(self, baseline_time: int) -> str:
        """ê¸°ì¤€ì‹œê°„ í‘œí˜„ ìƒì„±"""
        if baseline_time is None:
            return random.choice(self.baseline_status_expressions)
        else:
            expr = random.choice(self.baseline_expressions)
            return f"{expr} {baseline_time}ì´ˆ"
    
    def generate_input_data(self) -> Dict:
        """Input ë°ì´í„° ìƒì„±"""
        situation_type = self.select_situation_type()
        detection_time = self.generate_detection_time()
        baseline_time = self.generate_baseline_time(detection_time, situation_type)
        time = self.generate_time_expression()
        location = self.generate_location_with_area()
        detection_type = self.generate_detection_type()
        
        return {
            "situation_type": situation_type,
            "detection_time": detection_time,
            "baseline_time": baseline_time,
            "time": time,
            "location": location,
            "detection_type": detection_type
        }
    
    def generate_input_string(self, data: Dict) -> str:
        """Input ë¬¸ìì—´ ìƒì„±"""
        time = data["time"]
        location = data["location"]
        detection_type = data["detection_type"]
        detection_time = data["detection_time"]
        baseline_str = self.generate_baseline_expression(data["baseline_time"])
        
        # ë‹¤ì–‘í•œ Input í˜•ì‹ ìƒì„±
        formats = [
            f'"{time} {location}, {detection_type} ê°ì§€ {detection_time}ì´ˆ, {baseline_str}"',
            f'"{detection_type} ì¶œí˜„ {detection_time}ì´ˆ {location}, {baseline_str}, {time}"',
            f'"{time} {location}ì—ì„œ {detection_type}ì´ {detection_time}ì´ˆê°„ í¬ì°©ë˜ì—ˆìŠµë‹ˆë‹¤. {baseline_str}ì…ë‹ˆë‹¤."',
            f'"{detection_type} {detection_time}ì´ˆ {location} {time}, {baseline_str}"',
            f'"{location}ì—ì„œ {detection_type}ê°€ {detection_time}ì´ˆê°„ ê´€ì°°ë˜ì—ˆìœ¼ë©°, {time}, {baseline_str}ì…ë‹ˆë‹¤."'
        ]
        
        return random.choice(formats)
    
    def generate_situation_analysis(self, data: Dict) -> str:
        """ìƒí™© ë¶„ì„ ë¬¸ì¥ ìƒì„±"""
        detection_time = data["detection_time"]
        baseline_time = data["baseline_time"]
        detection_type = data["detection_type"]
        situation_type = data["situation_type"]
        location = data["location"]
        time = data["time"]
        
        if situation_type == "ê¸°ì¤€ì—†ìŒ":
            return f"{location}ì—ì„œ {time} {detection_type}ê°€ {detection_time}ì´ˆê°„ í¬ì°©ëœ ìƒí™©ì…ë‹ˆë‹¤"
        
        elif situation_type in ["ê·¹ë„ìœ„í—˜", "ìœ„í—˜ìƒí™©", "ì´ˆê³¼ìƒí™©"]:
            diff = detection_time - baseline_time
            baseline_expr = self.generate_baseline_expression(baseline_time).split()[0]  # "ê¸°ì¤€"ë§Œ ì¶”ì¶œ
            
            if situation_type == "ê·¹ë„ìœ„í—˜":
                return f"{location}ì—ì„œ {time} {detection_type}ê°€ {detection_time}ì´ˆê°„ ë°œìƒí•˜ì—¬ {baseline_expr} {baseline_time}ì´ˆë¥¼ {diff}ì´ˆ ì´ˆê³¼í•œ ê·¹ë„ë¡œ ìœ„í—˜í•œ ìƒí™©ì…ë‹ˆë‹¤"
            elif situation_type == "ìœ„í—˜ìƒí™©":
                return f"{location}ì—ì„œ {time} {detection_type}ê°€ {detection_time}ì´ˆê°„ ì§€ì†ë˜ì–´ {baseline_expr} {baseline_time}ì´ˆë¥¼ {diff}ì´ˆ ì´ˆê³¼í•œ ìœ„í—˜ ìƒí™©ì…ë‹ˆë‹¤"
            else:  # ì´ˆê³¼ìƒí™©
                return f"{location}ì—ì„œ {time} {detection_type}ê°€ {detection_time}ì´ˆê°„ ê°ì§€ë˜ì–´ {baseline_expr} {baseline_time}ì´ˆë¥¼ {diff}ì´ˆ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤"
        
        else:  # ì •ìƒìƒí™©
            baseline_expr = self.generate_baseline_expression(baseline_time).split()[0]
            return f"{location}ì—ì„œ {time} {detection_type}ê°€ {detection_time}ì´ˆê°„ ê´€ì°°ë˜ì–´ {baseline_expr} {baseline_time}ì´ˆë³´ë‹¤ {baseline_time - detection_time}ì´ˆ ì ì€ ì •ìƒ ë²”ìœ„ì…ë‹ˆë‹¤"
    
    def generate_immediate_action(self, data: Dict) -> str:
        """ì¦‰ì‹œ ì¡°ì¹˜ ë¬¸ì¥ ìƒì„±"""
        situation_type = data["situation_type"]
        location = data["location"]
        detection_type = data["detection_type"]
        
        # ìƒí™©ë³„ ê¸°ë³¸ ì¡°ì¹˜
        if situation_type == "ê·¹ë„ìœ„í—˜":
            base_action = random.choice(self.action_expressions["ê·¹ë„ìœ„í—˜"])
        elif situation_type == "ìœ„í—˜ìƒí™©":
            base_action = random.choice(self.action_expressions["ìœ„í—˜ìƒí™©"])
        elif situation_type == "ì´ˆê³¼ìƒí™©":
            base_action = random.choice(self.action_expressions["ì´ˆê³¼ìƒí™©"])
        elif situation_type == "ì •ìƒìƒí™©":
            base_action = random.choice(self.action_expressions["ì •ìƒìƒí™©"])
        else:  # ê¸°ì¤€ì—†ìŒ
            base_action = random.choice(self.action_expressions["ê¸°ì¤€ì—†ìŒ"])
        
        # ì¥ì†Œë³„ ë‹´ë‹¹ì ì¶”ê°€
        if "ê³µì¥" in location or "ì œì² ì†Œ" in location or "í™”í•™" in location:
            staff = random.choice(["ì•¼ê°„ ê´€ë¦¬ìê°€", "í˜„ì¥ ê´€ë¦¬ìê°€", "ì‘ì—…ìê°€"])
        elif "ë³‘ì›" in location or "ì˜ë£Œ" in location:
            staff = random.choice(["ì˜ë£Œì§„ì´", "ë³‘ì› ì§ì›ì´"])
        elif "í•™êµ" in location or "ëŒ€í•™" in location:
            staff = random.choice(["ë‹´ë‹¹ êµì‚¬ê°€", "ê´€ë¦¬ì§ì›ì´", "ë‹´ë‹¹ êµìˆ˜ê°€"])
        elif "í˜¸í…”" in location or "íœì…˜" in location:
            staff = random.choice(["í˜¸í…” ì§ì›ì´", "íœì…˜ ê´€ë¦¬ìê°€", "ëª¨í…” ê´€ë¦¬ìê°€"])
        else:
            staff = random.choice(["ì§ì›ì´", "ê´€ë¦¬ìê°€", "ë‹´ë‹¹ìê°€"])
        
        return f"{staff} {base_action}"
    
    def generate_additional_condition(self, data: Dict) -> str:
        """ì¶”ê°€ ì¡°ê±´ ë¬¸ì¥ ìƒì„±"""
        detection_time = data["detection_time"]
        situation_type = data["situation_type"]
        
        # ì¶”ê°€ ê°ì§€ ì‹œ ì¡°ì¹˜
        if situation_type in ["ê·¹ë„ìœ„í—˜", "ìœ„í—˜ìƒí™©"]:
            threshold = detection_time + random.randint(3, 8)
            actions = [
                f"ì¶”ê°€ {threshold}ì´ˆ ì´ìƒ ê°ì§€ë˜ë©´ ì „ì²´ ëŒ€í”¼ë¥¼ ê²€í† í•˜ì„¸ìš”",
                f"{threshold}ì´ˆ ì´ìƒ ì¶”ê°€ ê°ì§€ ì‹œ ì†Œë°©ëŒ€ ê¸´ê¸‰ ì¶œë™ì„ ìš”ì²­í•˜ì„¸ìš”",
                f"ì¶”ê°€ {threshold}ì´ˆ ì´ìƒ ê°ì§€ë˜ë©´ ê±´ë¬¼ ì „ì²´ í™”ì¬ ê²½ë³´ ë°œë ¹ì„ ê²€í† í•˜ì„¸ìš”"
            ]
        elif situation_type == "ì´ˆê³¼ìƒí™©":
            threshold = detection_time + random.randint(2, 5)
            actions = [
                f"ì¶”ê°€ {threshold}ì´ˆ ì´ìƒ ê°ì§€ ì‹œ ì•ˆì „ ì ê²€ì„ ìš”ì²­í•˜ì‹­ì‹œì˜¤",
                f"í–¥í›„ {threshold}ì´ˆ ì´ìƒ ì¬ë°œí•˜ë©´ ìš´ì˜ì„ ì¼ì‹œ ì¤‘ë‹¨í•˜ì‹œê¸° ê¶Œí•©ë‹ˆë‹¤",
                f"ë™ì¼ ìœ„ì¹˜ì—ì„œ {threshold}ì´ˆ ì´ìƒ ì§€ì†ë˜ë©´ ì‚¬ìš©ì„ ì¼ì‹œ ì¤‘ë‹¨í•˜ì„¸ìš”"
            ]
        elif situation_type == "ì •ìƒìƒí™©":
            threshold = detection_time + random.randint(1, 3)
            actions = [
                f"ì´í›„ {threshold}ì´ˆ ì´ìƒ ê°ì§€ ì‹œ ì „ê¸° ì•ˆì „ ì ê²€ì„ ì‹¤ì‹œí•˜ì„¸ìš”",
                f"í–¥í›„ {threshold}ì´ˆ ì´ìƒ ê°ì§€ë  ê²½ìš° ì¢…í•© ì•ˆì „ ì ê²€ì„ ì§„í–‰í•˜ì„¸ìš”",
                f"ë™ì¼ êµ¬ì—­ì—ì„œ {threshold}ì´ˆ ì´ìƒ ì¬ë°œ ì‹œ ì‚¬ìš©ì„ ì¼ì‹œ ì¤‘ë‹¨í•˜ì‹­ì‹œì˜¤"
            ]
        else:  # ê¸°ì¤€ì—†ìŒ
            threshold = detection_time + random.randint(2, 6)
            actions = [
                f"ë™ì¼ ìœ„ì¹˜ì—ì„œ {threshold}ì´ˆ ì´ìƒ ì¬ë°œ ì‹œ ì´ìš©ì„ ì¼ì‹œ ì¤‘ë‹¨í•˜ì‹œê¸° ê¶Œí•©ë‹ˆë‹¤",
                f"í–¥í›„ {threshold}ì´ˆ ì´ìƒ ì§€ì†ë˜ë©´ ì•ˆì „ ì ê²€ì„ ìš”ì²­í•˜ì‹­ì‹œì˜¤",
                f"ë™ì¼í•œ í˜„ìƒì´ {threshold}ì´ˆ ì´ìƒ ì§€ì†ë˜ë©´ í•´ë‹¹ êµ¬ì—­ ì¼ì‹œ í†µì œë¥¼ ê²€í† í•˜ì„¸ìš”"
            ]
        
        return random.choice(actions)
    
    def generate_output_content(self, data: Dict) -> str:
        """Output ë‚´ìš© ìƒì„±"""
        situation_analysis = self.generate_situation_analysis(data)
        immediate_action = self.generate_immediate_action(data)
        additional_condition = self.generate_additional_condition(data)
        
        # 2ë¬¸ì¥ (40%) ë˜ëŠ” 3ë¬¸ì¥ (60%)
        if random.random() < 0.4:
            # 2ë¬¸ì¥: ìƒí™©ë¶„ì„ + ì¡°ì¹˜
            return f"{situation_analysis}. {immediate_action}."
        else:
            # 3ë¬¸ì¥: ìƒí™©ë¶„ì„ + ì¦‰ì‹œì¡°ì¹˜ + ì¶”ê°€ì¡°ê±´
            return f"{situation_analysis}. {immediate_action}. {additional_condition}."
    
    def generate_single_data(self) -> Tuple[str, str, str]:
        """ë‹¨ì¼ ë°ì´í„° ìƒì„±"""
        input_data = self.generate_input_data()
        input_str = self.generate_input_string(input_data)
        output_str = self.generate_output_content(input_data)
        domain = "ì—°ê¸° ë° í™”ì—¼ ê°ì§€"
        
        return input_str, output_str, domain
    
    def generate_dataset(self, count: int) -> List[Tuple[str, str, str]]:
        """ë°ì´í„°ì…‹ ìƒì„±"""
        dataset = []
        
        print(f"ğŸ”„ ë„ë©”ì¸3 ë°ì´í„°ì…‹ {count}ê°œ ìƒì„± ì¤‘...")
        
        for i in range(count):
            if (i + 1) % 100 == 0:
                print(f"   ì§„í–‰ë¥ : {i + 1}/{count} ({((i + 1)/count)*100:.1f}%)")
            
            data = self.generate_single_data()
            dataset.append(data)
        
        print(f"âœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {count}ê°œ")
        return dataset
    
    def save_to_csv(self, dataset: List[Tuple[str, str, str]], filepath: str):
        """CSV íŒŒì¼ ì €ì¥"""
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile, quoting=csv.QUOTE_ALL)
            writer.writerow(['Input', 'Output', 'Domain'])
            for input_str, output_str, domain in dataset:
                writer.writerow([input_str, output_str, domain])
        
        print(f"ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filepath}")
    
    def validate_dataset(self, dataset: List[Tuple[str, str, str]]) -> Dict:
        """ë°ì´í„°ì…‹ ê²€ì¦"""
        total_count = len(dataset)
        
        # ìƒí™© ìœ í˜• ë¶„í¬
        situation_types = {"ê·¹ë„ìœ„í—˜": 0, "ìœ„í—˜ìƒí™©": 0, "ì´ˆê³¼ìƒí™©": 0, "ì •ìƒìƒí™©": 0, "ê¸°ì¤€ì—†ìŒ": 0}
        
        # ê°ì§€ ìœ í˜• ë¶„í¬
        detection_types = {"ì—°ê¸°": 0, "í™”ì—¼": 0, "ë¶ˆê½ƒ": 0, "ë³µí•©": 0}
        
        # ê°ì§€ ì‹œê°„ ë¶„í¬
        time_ranges = {"ë‹¨ê¸°(2-5ì´ˆ)": 0, "ì¤‘ê¸°(6-10ì´ˆ)": 0, "ì¥ê¸°(11-20ì´ˆ)": 0, "ì´ˆì¥ê¸°(21ì´ˆ+)": 0}
        
        # ë¬¸ì¥ ê¸¸ì´ ë¶„í¬
        sentence_lengths = {"2ë¬¸ì¥": 0, "3ë¬¸ì¥": 0, "ê¸°íƒ€": 0}
        
        for input_str, output_str, domain in dataset:
            # ìƒí™© ìœ í˜• ë¶„ë¥˜
            if "ê·¹ë„" in output_str:
                situation_types["ê·¹ë„ìœ„í—˜"] += 1
            elif "ìœ„í—˜" in output_str and ("ìˆ˜ì¤€" in output_str or "ìƒí™©" in output_str):
                situation_types["ìœ„í—˜ìƒí™©"] += 1
            elif "ì´ˆê³¼" in output_str:
                situation_types["ì´ˆê³¼ìƒí™©"] += 1
            elif "ì •ìƒ" in output_str or "ì•ˆì „í•œ" in output_str:
                situation_types["ì •ìƒìƒí™©"] += 1
            else:
                situation_types["ê¸°ì¤€ì—†ìŒ"] += 1
            
            # ê°ì§€ ìœ í˜• ë¶„ë¥˜
            if "ì—°ê¸°Â·í™”ì—¼" in input_str or "ë¶ˆê½ƒÂ·ì—°ê¸°" in input_str or "í™”ì—¼Â·ì—°ê¸°" in input_str:
                detection_types["ë³µí•©"] += 1
            elif "ì—°ê¸°" in input_str:
                detection_types["ì—°ê¸°"] += 1
            elif "í™”ì—¼" in input_str:
                detection_types["í™”ì—¼"] += 1
            elif "ë¶ˆê½ƒ" in input_str:
                detection_types["ë¶ˆê½ƒ"] += 1
            
            # ê°ì§€ ì‹œê°„ ì¶”ì¶œ
            time_match = re.search(r'(\d+)ì´ˆ', input_str)
            if time_match:
                detection_time = int(time_match.group(1))
                if detection_time <= 5:
                    time_ranges["ë‹¨ê¸°(2-5ì´ˆ)"] += 1
                elif detection_time <= 10:
                    time_ranges["ì¤‘ê¸°(6-10ì´ˆ)"] += 1
                elif detection_time <= 20:
                    time_ranges["ì¥ê¸°(11-20ì´ˆ)"] += 1
                else:
                    time_ranges["ì´ˆì¥ê¸°(21ì´ˆ+)"] += 1
            
            # ë¬¸ì¥ ê¸¸ì´ ì²´í¬ (í•œêµ­ì–´ ì¢…ê²°ì–´ë¯¸ í•µì‹¬ íŒ¨í„´ ê¸°ë°˜)
            sentence_endings_patterns = [
                r'ë‹¤\.',  # ~ë‹¤. (ìŠµë‹ˆë‹¤, ë©ë‹ˆë‹¤ ë“±)
                r'ìš”\.',  # ~ìš”. (í•´ì£¼ì„¸ìš” ë“±)  
                r'ì˜¤\.',  # ~ì˜¤. (í•˜ì‹­ì‹œì˜¤ ë“±)
            ]
            
            matched_positions = set()
            sentence_count = 0
            
            for pattern in sentence_endings_patterns:
                matches = re.finditer(pattern, output_str)
                for match in matches:
                    pos = match.end()
                    if pos not in matched_positions:
                        matched_positions.add(pos)
                        sentence_count += 1
            
            if sentence_count == 2:
                sentence_lengths["2ë¬¸ì¥"] += 1
            elif sentence_count == 3:
                sentence_lengths["3ë¬¸ì¥"] += 1
            else:
                sentence_lengths["ê¸°íƒ€"] += 1
        
        return {
            "total_count": total_count,
            "situation_types": {
                "ê·¹ë„ìœ„í—˜": f"{situation_types['ê·¹ë„ìœ„í—˜']} ({situation_types['ê·¹ë„ìœ„í—˜']/total_count*100:.1f}%)",
                "ìœ„í—˜ìƒí™©": f"{situation_types['ìœ„í—˜ìƒí™©']} ({situation_types['ìœ„í—˜ìƒí™©']/total_count*100:.1f}%)",
                "ì´ˆê³¼ìƒí™©": f"{situation_types['ì´ˆê³¼ìƒí™©']} ({situation_types['ì´ˆê³¼ìƒí™©']/total_count*100:.1f}%)",
                "ì •ìƒìƒí™©": f"{situation_types['ì •ìƒìƒí™©']} ({situation_types['ì •ìƒìƒí™©']/total_count*100:.1f}%)",
                "ê¸°ì¤€ì—†ìŒ": f"{situation_types['ê¸°ì¤€ì—†ìŒ']} ({situation_types['ê¸°ì¤€ì—†ìŒ']/total_count*100:.1f}%)"
            },
            "detection_types": {
                "ì—°ê¸°": f"{detection_types['ì—°ê¸°']} ({detection_types['ì—°ê¸°']/total_count*100:.1f}%)",
                "í™”ì—¼": f"{detection_types['í™”ì—¼']} ({detection_types['í™”ì—¼']/total_count*100:.1f}%)",
                "ë¶ˆê½ƒ": f"{detection_types['ë¶ˆê½ƒ']} ({detection_types['ë¶ˆê½ƒ']/total_count*100:.1f}%)",
                "ë³µí•©": f"{detection_types['ë³µí•©']} ({detection_types['ë³µí•©']/total_count*100:.1f}%)"
            },
            "time_ranges": {
                "ë‹¨ê¸°(2-5ì´ˆ)": f"{time_ranges['ë‹¨ê¸°(2-5ì´ˆ)']} ({time_ranges['ë‹¨ê¸°(2-5ì´ˆ)']/total_count*100:.1f}%)",
                "ì¤‘ê¸°(6-10ì´ˆ)": f"{time_ranges['ì¤‘ê¸°(6-10ì´ˆ)']} ({time_ranges['ì¤‘ê¸°(6-10ì´ˆ)']/total_count*100:.1f}%)",
                "ì¥ê¸°(11-20ì´ˆ)": f"{time_ranges['ì¥ê¸°(11-20ì´ˆ)']} ({time_ranges['ì¥ê¸°(11-20ì´ˆ)']/total_count*100:.1f}%)",
                "ì´ˆì¥ê¸°(21ì´ˆ+)": f"{time_ranges['ì´ˆì¥ê¸°(21ì´ˆ+)']} ({time_ranges['ì´ˆì¥ê¸°(21ì´ˆ+)']/total_count*100:.1f}%)"
            },
            "sentence_lengths": {
                "2ë¬¸ì¥": f"{sentence_lengths['2ë¬¸ì¥']} ({sentence_lengths['2ë¬¸ì¥']/total_count*100:.1f}%)",
                "3ë¬¸ì¥": f"{sentence_lengths['3ë¬¸ì¥']} ({sentence_lengths['3ë¬¸ì¥']/total_count*100:.1f}%)",
                "ê¸°íƒ€": f"{sentence_lengths['ê¸°íƒ€']} ({sentence_lengths['ê¸°íƒ€']/total_count*100:.1f}%)"
            }
        }

if __name__ == "__main__":
    """
    ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
    - 1000ê°œ ë°ì´í„°ì…‹ ìƒì„±
    - CSV íŒŒì¼ ì €ì¥
    - ê²€ì¦ ê²°ê³¼ ì¶œë ¥
    """
    # ë°ì´í„°ì…‹ ìƒì„±ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    generator = Domain3SmokeFlameDetectionGenerator()
    
    # 1000ê°œ ë°ì´í„°ì…‹ ìƒì„±
    dataset = generator.generate_dataset(5000)
    
    # ì €ì¥ ê²½ë¡œ ì„¤ì •
    output_path = os.path.join(os.path.dirname(__file__), '..', 'csv', 'domain3_dataset.csv')
    generator.save_to_csv(dataset, output_path)
    
    # ë°ì´í„°ì…‹ ê²€ì¦ ë° ê²°ê³¼ ì¶œë ¥
    validation_results = generator.validate_dataset(dataset)
    
    print(f"\nâœ… ë„ë©”ì¸3 ë°ì´í„°ì…‹ 1000ê°œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
    print("\nğŸ“Š ë°ì´í„°ì…‹ ê²€ì¦ ê²°ê³¼:")
    print(f"   ì´ ë°ì´í„° ê°œìˆ˜: {validation_results['total_count']}ê°œ")
    print(f"\nâš ï¸ ìƒí™© ìœ í˜• ë¶„í¬:")
    print(f"   ê·¹ë„ìœ„í—˜: {validation_results['situation_types']['ê·¹ë„ìœ„í—˜']}")
    print(f"   ìœ„í—˜ìƒí™©: {validation_results['situation_types']['ìœ„í—˜ìƒí™©']}")
    print(f"   ì´ˆê³¼ìƒí™©: {validation_results['situation_types']['ì´ˆê³¼ìƒí™©']}")
    print(f"   ì •ìƒìƒí™©: {validation_results['situation_types']['ì •ìƒìƒí™©']}")
    print(f"   ê¸°ì¤€ì—†ìŒ: {validation_results['situation_types']['ê¸°ì¤€ì—†ìŒ']}")
    print(f"\nğŸ”¥ ê°ì§€ ìœ í˜• ë¶„í¬:")
    print(f"   ì—°ê¸°: {validation_results['detection_types']['ì—°ê¸°']}")
    print(f"   í™”ì—¼: {validation_results['detection_types']['í™”ì—¼']}")
    print(f"   ë¶ˆê½ƒ: {validation_results['detection_types']['ë¶ˆê½ƒ']}")
    print(f"   ë³µí•©: {validation_results['detection_types']['ë³µí•©']}")
    print(f"\nâ±ï¸ ê°ì§€ ì‹œê°„ ë¶„í¬:")
    print(f"   ë‹¨ê¸°(2-5ì´ˆ): {validation_results['time_ranges']['ë‹¨ê¸°(2-5ì´ˆ)']}")
    print(f"   ì¤‘ê¸°(6-10ì´ˆ): {validation_results['time_ranges']['ì¤‘ê¸°(6-10ì´ˆ)']}")
    print(f"   ì¥ê¸°(11-20ì´ˆ): {validation_results['time_ranges']['ì¥ê¸°(11-20ì´ˆ)']}")
    print(f"   ì´ˆì¥ê¸°(21ì´ˆ+): {validation_results['time_ranges']['ì´ˆì¥ê¸°(21ì´ˆ+)']}")
    print(f"\nğŸ“ ë¬¸ì¥ ê¸¸ì´ ë¶„í¬:")
    print(f"   2ë¬¸ì¥: {validation_results['sentence_lengths']['2ë¬¸ì¥']}")
    print(f"   3ë¬¸ì¥: {validation_results['sentence_lengths']['3ë¬¸ì¥']}")
    print(f"   ê¸°íƒ€: {validation_results['sentence_lengths']['ê¸°íƒ€']}")