#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë„ë©”ì¸10 ì´ìƒ ì´ë™ íŒ¨í„´ ê°ì§€ ë°ì´í„°ì…‹ ìƒì„±ê¸°
template8.pyì™€ template9.py êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ Domain10 ì „ìš© ìƒì„±ê¸°

ì£¼ìš” ê¸°ëŠ¥:
- 7ê°€ì§€ ì´ìƒ ì´ë™ íŒ¨í„´ë³„ ê°ì§€ ë°ì´í„° ìƒì„± (ë™ì„  ì´íƒˆ, ê¶¤ì  ë°˜ë³µ, ë¹„ì •ìƒ ë°©í–¥ ì „í™˜, ê³ ì† ì´ë™, ê¸‰ì •ì§€, ì •ì§€ í›„ ì¬ì´ë™, êµ¬ì—­ ê²½ë¡œ ìš°íšŒ)
- ì‚¬ëŒ/ì°¨ëŸ‰ ê°ì²´ë³„ ë‹¤ì–‘í•œ ìƒí™© ì‹œë®¬ë ˆì´ì…˜
- ê±°ë¦¬/ì‹œê°„ ê¸°ë°˜ ì¸¡ì •ê°’ê³¼ ê¸°ì¤€ê°’ ë¹„êµ
- ê¸°ì¤€ ì„¤ì •/ë¯¸ì„¤ì • ìƒí™© ì²˜ë¦¬
- êµ¬ì¡°í˜•/ì„¤ëª…í˜• Input ìƒì„± (60:40 ë¹„ìœ¨)
- 2~4ë¬¸ì¥ ìì—°ìŠ¤ëŸ¬ìš´ Output ìƒì„±
- 1000ê°œ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ìƒì„±
"""

import random
import csv
import json
import os
import re
from typing import List, Dict, Tuple, Set
from collections import Counter

class Domain10AbnormalMovementGenerator:
    """
    ë„ë©”ì¸10 ì´ìƒ ì´ë™ íŒ¨í„´ ê°ì§€ ë°ì´í„°ì…‹ ìƒì„±ê¸°
    """
    
    def __init__(self):
        """ìƒì„±ê¸° ì´ˆê¸°í™” - ëª¨ë“  ì„¤ì •ê°’ê³¼ íŒ¨í„´ ì •ì˜"""
        
        # ì´ìƒ ì´ë™ íŒ¨í„´ ìœ í˜•ë³„ ì„¤ì • (7ê°€ì§€ ì£¼ìš” íŒ¨í„´)
        self.movement_patterns = {
            "ë™ì„  ì´íƒˆ": {"weight": 18, "unit_types": ["distance", "time"]},
            "ê¶¤ì  ë°˜ë³µ": {"weight": 17, "unit_types": ["distance", "time"]},
            "ë¹„ì •ìƒ ë°©í–¥ ì „í™˜": {"weight": 16, "unit_types": ["distance", "time"]},
            "ê³ ì† ì´ë™": {"weight": 15, "unit_types": ["distance", "time"]},
            "ê¸‰ì •ì§€": {"weight": 14, "unit_types": ["distance", "time"]},
            "ì •ì§€ í›„ ì¬ì´ë™": {"weight": 12, "unit_types": ["distance", "time"]},
            "êµ¬ì—­ ê²½ë¡œ ìš°íšŒ": {"weight": 8, "unit_types": ["distance", "time"]}
        }
        
        # ê°ì²´ ìœ í˜• ì„¤ì • (ì‚¬ëŒ + ì°¨ëŸ‰)
        self.person_types = ["ë°©ë¬¸ì", "ì§ì›", "ì™¸ë¶€ì¸", "í•™ìƒ", "í™˜ì", "ìŠ¹ê°", "ë³´í–‰ì"]
        self.vehicle_types = ["ìŠ¹ìš©ì°¨", "íŠ¸ëŸ­", "ì§€ê²Œì°¨"]
        
        # ì¸¡ì • ë‹¨ìœ„ ì„¤ì •
        self.measurement_units = {
            "distance": {
                "unit": "m",
                "formats": ["{value}m", "{value}mê°„"],  # 70% vs 30%
                "ranges": {
                    "ì§§ìŒ": {"min": 3, "max": 8, "weight": 30},
                    "ë³´í†µ": {"min": 9, "max": 15, "weight": 40},
                    "ê¹€": {"min": 16, "max": 20, "weight": 30}
                }
            },
            "time": {
                "unit": "ì´ˆ",
                "formats": ["{value}ì´ˆ", "{value}ì´ˆê°„"],  # 70% vs 30%
                "ranges": {
                    "ì§§ìŒ": {"min": 3, "max": 7, "weight": 35},
                    "ë³´í†µ": {"min": 8, "max": 12, "weight": 40},
                    "ê¹€": {"min": 13, "max": 20, "weight": 25}
                }
            }
        }
        
        # ì¥ì†Œ ì„¤ì • (ì‹¤ë‚´Â·ì‹¤ì™¸ ë‹¤ì–‘í•œ ì‹¤ì œ ì¥ì†Œ)
        self.locations = {
            # ë‹¨ìˆœ ì¥ì†Œ (30-40%)
            "simple": [
                "ë¬¼ë¥˜ì„¼í„°", "ê³µì¥", "ì‚¬ë¬´ì‹¤", "ë³‘ì›", "í•™êµ", "ê³µí•­", "ì£¼ì°¨ì¥", "ìš´ë™ì¥",
                "ë¡œë¹„", "ì¶œêµ­ì¥", "ì…êµ¬", "ì¶œêµ¬", "ë³µë„", "ê³„ë‹¨", "ì—˜ë¦¬ë² ì´í„°"
            ],
            # ì¥ì†Œ+êµ¬ì—­ëª… (60-70%)
            "complex": [
                "ë¬¼ë¥˜ì„¼í„° Aêµ¬ì—­", "ë¬¼ë¥˜ì„¼í„° Bêµ¬ì—­", "ê³µì¥ Aë™", "ê³µì¥ Bë™", "ê³µì¥ Cë™",
                "ì‚¬ë¬´ì‹¤ Aêµ¬ì—­", "ì‚¬ë¬´ì‹¤ Bêµ¬ì—­", "ì‚¬ë¬´ì‹¤ Cêµ¬ì—­", "ë³‘ì› ì‘ê¸‰ì‹¤ ë¡œë¹„",
                "í•™êµ ìš´ë™ì¥", "ê³µí•­ ì¶œêµ­ì¥", "ê³µí•­ ì…êµ­ì¥", "ì£¼ì°¨ì¥ Aêµ¬ì—­", 
                "ì£¼ì°¨ì¥ Bêµ¬ì—­", "ì£¼ì°¨ì¥ Cêµ¬ì—­", "ì£¼ì°¨ì¥ Dêµ¬ì—­", "Aêµ¬ì—­", "Bêµ¬ì—­", 
                "Cêµ¬ì—­", "Dêµ¬ì—­", "Eêµ¬ì—­", "Fêµ¬ì—­", "1ì¸µ ë¡œë¹„", "2ì¸µ ëŒ€ê¸°ì‹¤",
                "ì§€í•˜1ì¸µ", "ì˜¥ìƒ", "ì¤‘ì•™ê´‘ì¥", "íœ´ê²Œì‹¤", "íšŒì˜ì‹¤", "ëŒ€ê¸°ì‹¤"
            ]
        }
        
        # ê¸°ì¤€ ì„¤ì • ìœ í˜•
        self.baseline_types = {
            "ê¸°ì¤€ìˆìŒ": {
                "weight": 70,  # ê¸°ì¤€ ìˆìŒ 70%
                "formats": ["ê¸°ì¤€: {value}{unit}", "ê¸°ì¤€ {value}{unit}"]
            },
            "ê¸°ì¤€ì—†ìŒ": {
                "weight": 30,  # ê¸°ì¤€ ì—†ìŒ 30%
                "formats": ["í—ˆìš©ì¹˜ ì—†ìŒ", "ê¸°ì¤€ ë¯¸ì„¤ì •", "ê¸°ì¤€ ì—†ìŒ", "í—ˆìš©ì¹˜ ë¯¸ì„¤ì •"]
            }
        }
        
        # ìœ„í—˜ë„ ë¶„ë¥˜ ë¹„ìœ¨ (ì„¤ê³„ì„œ ê¸°ì¤€)
        self.risk_categories = {
            "ìœ„í—˜": {"weight": 70, "threshold_ratio": 1.2},    # ê¸°ì¤€ ì´ˆê³¼ ì‹œ 70%
            "ì£¼ì˜": {"weight": 20, "threshold_ratio": 0.9},    # ëª¨ë‹ˆí„°ë§ ê°•í™” 20%
            "ì •ìƒ": {"weight": 10, "threshold_ratio": 0.8}     # ì •ìƒ/ê´€ì°° 10%
        }
        
        # ìƒí™© ë¶„ì„ í‘œí˜„
        self.situation_expressions = {
            "detection_verbs": [
                "ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤", "íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤", "í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤",
                "í¬ì°©ë˜ì—ˆìŠµë‹ˆë‹¤", "ê´€ì¸¡ë˜ì—ˆìŠµë‹ˆë‹¤", "ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤"
            ],
            "over_standard": [
                "ê¸°ì¤€ {baseline}{unit}ë¥¼ {diff}{unit} ì´ˆê³¼í•˜ì—¬ ì´ìƒ í–‰ë™ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤",
                "ê¸°ì¤€ {baseline}{unit}ë¥¼ {diff}{unit} ë„˜ì–´ì„œ ë¹„ì •ìƒ ì´ë™ìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤",
                "ê¸°ì¤€ì¹˜ {baseline}{unit}ë¥¼ {diff}{unit} ìƒíšŒí•˜ì—¬ ìœ„í—˜ ìƒí™©ì…ë‹ˆë‹¤"
            ],
            "within_standard": [
                "ì¸¡ì •ê°’ì´ ê¸°ì¤€ {baseline}{unit}ì— ë¶€í•©í•˜ì—¬ ì •ìƒ ë²”ìœ„ë¡œ í‰ê°€ë©ë‹ˆë‹¤",
                "ê¸°ì¤€ {baseline}{unit} ë²”ìœ„ì—ì„œ ì •ìƒ ì´ë™ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤",
                "ê¸°ì¤€ì¹˜ {baseline}{unit} ë‚´ì—ì„œ ì–‘í˜¸í•œ ìƒíƒœë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤"
            ],
            "no_standard": [
                "ê¸°ì¤€ì´ ì •ì˜ë˜ì§€ ì•Šì•„ ì¶”ê°€ íŒë‹¨ì´ ë¶ˆê°€í•˜ë‹ˆ ê´€ì°° ìƒíƒœë¥¼ ìœ ì§€í•˜ì„¸ìš”",
                "í—ˆìš© ê¸°ì¤€ì´ ë¯¸ì„¤ì •ë˜ì–´ ì¦‰ê°ì  ì¡°ì¹˜ ëŒ€ì‹  ê´€ì°°ë§Œ ì‹¤ì‹œí•˜ì‹­ì‹œì˜¤",
                "ê¸°ì¤€ì¹˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì€ êµ¬ì—­ì´ë¯€ë¡œ ëª¨ë‹ˆí„°ë§ë§Œ ì§„í–‰í•˜ì‹­ì‹œì˜¤",
                "ê¸°ì¤€ì¹˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ê´€ì°°ë§Œ ìœ ì§€í•˜ì„¸ìš”"
            ]
        }
        
        # ì¡°ì¹˜ í‘œí˜„
        self.action_expressions = {
            "immediate": [
                "ë³´ì•ˆíŒ€ì€ ì¦‰ì‹œ í˜„ì¥ í™•ì¸í•˜ì„¸ìš”",
                "ë³´ì•ˆìš”ì›ì˜ ì¦‰ì‹œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤",
                "ê¸´ê¸‰ ëŒ€ì‘ì´ í•„ìš”í•©ë‹ˆë‹¤",
                "ì¦‰ê°ì ì¸ ì¡°ì¹˜ê°€ ìš”êµ¬ë©ë‹ˆë‹¤"
            ],
            "warning": [
                "ìœ„í—˜ ê²½ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤",
                "ì£¼ì˜ê°€ ìš”êµ¬ë©ë‹ˆë‹¤",
                "ê²½ê³„ ê°•í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            ],
            "monitoring": [
                "ë°˜ë³µ ì‹œ ì ê²€ì„ ê¶Œì¥í•©ë‹ˆë‹¤",
                "ì§€ì† ëª¨ë‹ˆí„°ë§ì„ ê¶Œì¥í•©ë‹ˆë‹¤",
                "í–¥í›„ ê´€ì°°ì´ í•„ìš”í•©ë‹ˆë‹¤",
                "ê³„ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì´ ìš”êµ¬ë©ë‹ˆë‹¤"
            ],
            "observation": [
                "ì§€ì† ëª¨ë‹ˆí„°ë§ì„ ê¶Œì¥í•©ë‹ˆë‹¤",
                "ê´€ì°°ë§Œ ìœ ì§€í•˜ì„¸ìš”",
                "ëª¨ë‹ˆí„°ë§ë§Œ ì§„í–‰í•˜ì‹­ì‹œì˜¤"
            ]
        }
        
        # ì¶”ê°€ ì„¤ëª… í‘œí˜„ (3-4ë¬¸ì¥ êµ¬ì„±ìš©)
        self.additional_explanations = [
            "í•´ë‹¹ í–‰ë™ì€ ë¹„ì •ìƒ ì´ë™ íŒ¨í„´ìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤",
            "ì¸¡ì •ëœ ì´ë™ íŒ¨í„´ì´ ê¸°ì¤€ì¹˜ë¥¼ ì´ˆê³¼í•œ ì›ì¸ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤",
            "{pattern} íŒ¨í„´ì´ ì§€ì†ì ìœ¼ë¡œ ë°œìƒí•œ ê²ƒìœ¼ë¡œ í™•ì¸ë©ë‹ˆë‹¤"
        ]
        
        # Input êµ¬ì¡°í˜•/ì„¤ëª…í˜• íŒ¨í„´
        self.input_patterns = {
            "structured": {  # êµ¬ì¡°í˜• 60%
                "weight": 60,
                "templates": [
                    "{time} {location}ì—ì„œ {object}ì´ {pattern} {measurement}, {baseline}",
                    "{baseline}, {time} {location}ì—ì„œ {object}ì´ {pattern} {measurement}",
                    "{object}ì´ {time}ì— {location}ì—ì„œ {pattern} {measurement}, {baseline}",
                    "{location}ì—ì„œ {time}ì— {object}ì´ {pattern} {measurement}, {baseline}",
                    "{time}ì— {object}ì´ {pattern} í›„ {measurement} ì´ë™í–ˆìŠµë‹ˆë‹¤, {baseline}"
                ]
            },
            "descriptive": {  # ì„¤ëª…í˜• 40%
                "weight": 40,
                "templates": [
                    "{time}ì— {object}ì´ {pattern} í–‰ë™ì„ ë³´ì˜€ìœ¼ë©° {measurement} ë¨¸ë¬¼ë €ìŠµë‹ˆë‹¤, {baseline}",
                    "{object}ì´ {time}ì— {location}ì—ì„œ {pattern} ë™ì‘ì„ ë³´ì˜€ìœ¼ë©° {measurement} ë¨¸ë¬¼ë €ìŠµë‹ˆë‹¤, {baseline}",
                    "{baseline}, {time} {object}ì´ {location}ì—ì„œ {pattern}ì„ {measurement} ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤",
                    "{time}ì— {object}ì´ {pattern} í›„ {measurement} ì´ë™í–ˆìŠµë‹ˆë‹¤, {baseline}"
                ]
            }
        }
        
    def generate_time_format(self) -> str:
        """ì‹œê°„ í˜•ì‹ ìƒì„± (HH:MM 50% / í•œê¸€ ì‹œê°„ 50%)"""
        hour = random.randint(0, 23)
        minute = random.randint(0, 59)
        
        if random.random() < 0.5:
            # HH:MM í˜•ì‹ (50%)
            return f"{hour:02d}:{minute:02d}"
        else:
            # í•œê¸€ ì‹œê°„ í˜•ì‹ (50%)
            time_labels = {
                0: "ìì •", 1: "ìƒˆë²½", 2: "ì•„ì¹¨", 3: "ì•„ì¹¨", 4: "ì•„ì¹¨", 5: "ì•„ì¹¨",
                6: "ì˜¤ì „", 7: "ì˜¤ì „", 8: "ì˜¤ì „", 9: "ì˜¤ì „", 10: "ì˜¤ì „", 11: "ì˜¤ì „",
                12: "ì •ì˜¤", 13: "ì˜¤í›„", 14: "ì˜¤í›„", 15: "ì˜¤í›„", 16: "ì˜¤í›„", 17: "ì˜¤í›„",
                18: "ì €ë…", 19: "ì €ë…", 20: "ì €ë…", 21: "ì €ë…", 22: "ë°¤", 23: "ë°¤"
            }
            
            label = time_labels[hour]
            if hour == 0:
                return f"{label} 12ì‹œ {minute}ë¶„"
            elif hour == 12:
                return f"{label} 12ì‹œ {minute}ë¶„"
            elif hour > 12:
                return f"{label} {hour-12}ì‹œ {minute}ë¶„"
            else:
                return f"{label} {hour}ì‹œ {minute}ë¶„"
    
    def generate_location(self) -> str:
        """ì¥ì†Œ ìƒì„± (ë‹¨ìˆœ ì¥ì†Œ 30-40% / ì¥ì†Œ+êµ¬ì—­ëª… 60-70%)"""
        if random.random() < 0.35:  # 35% ë‹¨ìˆœ ì¥ì†Œ
            return random.choice(self.locations["simple"])
        else:  # 65% ì¥ì†Œ+êµ¬ì—­ëª…
            return random.choice(self.locations["complex"])
    
    def generate_object(self) -> str:
        """ê°ì²´ ìƒì„± (ì‚¬ëŒ ë˜ëŠ” ì°¨ëŸ‰)"""
        if random.random() < 0.7:  # 70% ì‚¬ëŒ
            person = random.choice(self.person_types)
            return f"{person} 1ëª…"
        else:  # 30% ì°¨ëŸ‰
            vehicle = random.choice(self.vehicle_types)
            return f"{vehicle} 1ëŒ€"
    
    def generate_pattern_and_measurement(self) -> Dict:
        """íŒ¨í„´ê³¼ ì¸¡ì •ê°’ ìƒì„±"""
        # íŒ¨í„´ ì„ íƒ
        pattern_weights = [self.movement_patterns[p]["weight"] for p in self.movement_patterns.keys()]
        pattern = random.choices(list(self.movement_patterns.keys()), weights=pattern_weights)[0]
        
        # ì¸¡ì • ë‹¨ìœ„ ì„ íƒ (ê±°ë¦¬ ë˜ëŠ” ì‹œê°„)
        unit_type = random.choice(list(self.measurement_units.keys()))
        unit_info = self.measurement_units[unit_type]
        
        # ì¸¡ì •ê°’ ë²”ìœ„ ì„ íƒ
        range_weights = [unit_info["ranges"][r]["weight"] for r in unit_info["ranges"].keys()]
        selected_range = random.choices(list(unit_info["ranges"].keys()), weights=range_weights)[0]
        range_info = unit_info["ranges"][selected_range]
        
        # ì¸¡ì •ê°’ ìƒì„±
        value = random.randint(range_info["min"], range_info["max"])
        
        # ì¸¡ì •ê°’ í˜•ì‹ ì„ íƒ (Nì´ˆ 70% vs Nì´ˆê°„ 30%)
        format_choice = random.choices(unit_info["formats"], weights=[70, 30])[0]
        measurement_text = format_choice.format(value=value)
        
        return {
            "pattern": pattern,
            "unit_type": unit_type,
            "unit": unit_info["unit"],
            "value": value,
            "measurement_text": measurement_text
        }
    
    def generate_baseline(self, measurement_info: Dict) -> Dict:
        """ê¸°ì¤€ê°’ ìƒì„±"""
        # ê¸°ì¤€ ì„¤ì • ì—¬ë¶€ ê²°ì •
        baseline_weights = [self.baseline_types[bt]["weight"] for bt in self.baseline_types.keys()]
        baseline_type = random.choices(list(self.baseline_types.keys()), weights=baseline_weights)[0]
        
        if baseline_type == "ê¸°ì¤€ìˆìŒ":
            # ê¸°ì¤€ê°’ ìƒì„±
            current_value = measurement_info["value"]
            
            # ìœ„í—˜ë„ ë¶„ë¥˜ì— ë”°ë¥¸ ê¸°ì¤€ê°’ ì„¤ì •
            risk_weights = [self.risk_categories[r]["weight"] for r in self.risk_categories.keys()]
            risk_type = random.choices(list(self.risk_categories.keys()), weights=risk_weights)[0]
            
            if risk_type == "ìœ„í—˜":  # ê¸°ì¤€ ì´ˆê³¼ (70%)
                baseline_value = random.randint(max(1, current_value - 8), current_value - 1)
            elif risk_type == "ì •ìƒ":  # ê¸°ì¤€ ë‚´ (10%)
                baseline_value = random.randint(current_value + 1, current_value + 8)
            else:  # ì£¼ì˜ (20%) - ê±°ì˜ ê¸°ì¤€ì— ê·¼ì ‘
                if random.random() < 0.5:
                    baseline_value = current_value  # ì •í™•íˆ ê¸°ì¤€ê³¼ ë™ì¼
                else:
                    baseline_value = random.randint(max(1, current_value - 2), current_value + 2)
            
            format_template = random.choice(self.baseline_types[baseline_type]["formats"])
            baseline_text = format_template.format(value=baseline_value, unit=measurement_info["unit"])
            
            return {
                "has_baseline": True,
                "baseline_value": baseline_value,
                "baseline_text": baseline_text,
                "is_over": current_value > baseline_value,
                "risk_type": risk_type
            }
        else:
            # ê¸°ì¤€ ì—†ìŒ
            baseline_text = random.choice(self.baseline_types[baseline_type]["formats"])
            return {
                "has_baseline": False,
                "baseline_value": None,
                "baseline_text": baseline_text,
                "is_over": False,
                "risk_type": "ê¸°ì¤€ì—†ìŒ"
            }
    
    def generate_input_text(self, input_data: Dict) -> str:
        """Input í…ìŠ¤íŠ¸ ìƒì„±"""
        # êµ¬ì¡°í˜•/ì„¤ëª…í˜• ì„ íƒ
        input_weights = [self.input_patterns[t]["weight"] for t in self.input_patterns.keys()]
        input_type = random.choices(list(self.input_patterns.keys()), weights=input_weights)[0]
        
        # í…œí”Œë¦¿ ì„ íƒ
        template = random.choice(self.input_patterns[input_type]["templates"])
        
        # í…œí”Œë¦¿ì— ë°ì´í„° ì ìš©
        input_text = template.format(
            time=input_data["time"],
            location=input_data["location"],
            object=input_data["object"],
            pattern=input_data["pattern_info"]["pattern"],
            measurement=input_data["pattern_info"]["measurement_text"],
            baseline=input_data["baseline_info"]["baseline_text"]
        )
        
        return input_text
    
    def generate_situation_analysis(self, input_data: Dict) -> str:
        """ìƒí™© ë¶„ì„ ë¬¸ì¥ ìƒì„±"""
        time = input_data["time"]
        location = input_data["location"]
        object_str = input_data["object"]
        pattern_info = input_data["pattern_info"]
        
        # ê°ì§€ ë™ì‚¬ ì„ íƒ
        detection_verb = random.choice(self.situation_expressions["detection_verbs"])
        
        # ê¸°ë³¸ ìƒí™© ë¬¸ì¥ (ì‹œì‘ì  ë‹¤ì–‘í™”)
        start_patterns = [
            f"{time}ì— {location}ì—ì„œ {object_str}ì´ {pattern_info['measurement_text']} {pattern_info['pattern']} {detection_verb}",  # 40%
            f"{location}ì—ì„œ {time}ì— {object_str}ì´ {pattern_info['measurement_text']} {pattern_info['pattern']} {detection_verb}",   # 20%
            f"{object_str}ì´ {time}ì— {location}ì—ì„œ {pattern_info['measurement_text']} {pattern_info['pattern']} {detection_verb}",   # 20%
            f"{pattern_info['measurement_text']} {pattern_info['pattern']}ì´ {time}ì— {location}ì—ì„œ {detection_verb}"  # 20%
        ]
        
        weights = [40, 20, 20, 20]
        situation_base = random.choices(start_patterns, weights=weights)[0]
        
        return situation_base
    
    def generate_evaluation_sentence(self, input_data: Dict) -> str:
        """í‰ê°€ ë¬¸ì¥ ìƒì„±"""
        pattern_info = input_data["pattern_info"]
        baseline_info = input_data["baseline_info"]
        
        if not baseline_info["has_baseline"]:
            # ê¸°ì¤€ ì—†ìŒ
            return random.choice(self.situation_expressions["no_standard"])
        elif baseline_info["is_over"]:
            # ê¸°ì¤€ ì´ˆê³¼
            diff = pattern_info["value"] - baseline_info["baseline_value"]
            expr = random.choice(self.situation_expressions["over_standard"])
            return expr.format(
                baseline=baseline_info["baseline_value"],
                unit=pattern_info["unit"],
                diff=diff
            )
        else:
            # ê¸°ì¤€ ë‚´
            expr = random.choice(self.situation_expressions["within_standard"])
            return expr.format(
                baseline=baseline_info["baseline_value"],
                unit=pattern_info["unit"]
            )
    
    def generate_action_sentence(self, input_data: Dict) -> str:
        """ì¡°ì¹˜ ë¬¸ì¥ ìƒì„±"""
        baseline_info = input_data["baseline_info"]
        
        if not baseline_info["has_baseline"]:
            # ê¸°ì¤€ ì—†ìŒ - ê´€ì°°
            return random.choice(self.action_expressions["observation"])
        elif baseline_info["is_over"]:
            # ê¸°ì¤€ ì´ˆê³¼ - ì¦‰ì‹œ ì¡°ì¹˜ ë˜ëŠ” ê²½ê³ 
            if random.random() < 0.8:  # 80% ì¦‰ì‹œ ì¡°ì¹˜
                return random.choice(self.action_expressions["immediate"])
            else:  # 20% ê²½ê³ 
                return random.choice(self.action_expressions["warning"])
        else:
            # ê¸°ì¤€ ë‚´ - ëª¨ë‹ˆí„°ë§
            return random.choice(self.action_expressions["monitoring"])
    
    def generate_natural_output(self, input_data: Dict) -> str:
        """ìì—°ìŠ¤ëŸ¬ìš´ 2~4ë¬¸ì¥ Output ìƒì„±"""
        situation = self.generate_situation_analysis(input_data)
        evaluation = self.generate_evaluation_sentence(input_data)
        action = self.generate_action_sentence(input_data)
        
        # ë¬¸ì¥ ìˆ˜ ê²°ì • (2ë¬¸ì¥: 40%, 3ë¬¸ì¥: 45%, 4ë¬¸ì¥: 15%)
        sentence_count = random.choices([2, 3, 4], weights=[40, 45, 15])[0]
        
        if sentence_count == 2:
            # 2ë¬¸ì¥: [ìƒí™©] + [í‰ê°€+ì¡°ì¹˜]
            return f"{situation}. {evaluation}. {action}."
        elif sentence_count == 3:
            # 3ë¬¸ì¥ íŒ¨í„´ ì„ íƒ
            patterns = [
                # íŒ¨í„´ 1: [ìƒí™©] + [í‰ê°€] + [ì¡°ì¹˜]
                lambda: f"{situation}. {evaluation}. {action}.",
                
                # íŒ¨í„´ 2: [ìƒí™©] + [ì¶”ê°€ì„¤ëª…] + [í‰ê°€+ì¡°ì¹˜]
                lambda: f"{situation}. {random.choice(self.additional_explanations).format(pattern=input_data['pattern_info']['pattern'])}. {evaluation}. {action}.",
                
                # íŒ¨í„´ 3: [í‰ê°€] + [ì¡°ì¹˜] + [ìƒí™©]
                lambda: f"{evaluation}. {action}. {situation}."
            ]
            
            selected_pattern = random.choice(patterns)
            return selected_pattern()
        else:  # 4ë¬¸ì¥
            # 4ë¬¸ì¥: [ìƒí™©] + [ì¶”ê°€ì„¤ëª…] + [í‰ê°€] + [ì¡°ì¹˜]
            additional = random.choice(self.additional_explanations).format(pattern=input_data['pattern_info']['pattern'])
            return f"{situation}. {additional}. {evaluation}. {action}."
    
    def generate_single_data(self) -> Tuple[str, str, str]:
        """ë‹¨ì¼ ë°ì´í„° ìƒì„±"""
        # ê¸°ë³¸ ë°ì´í„° ìƒì„±
        time = self.generate_time_format()
        location = self.generate_location()
        object_str = self.generate_object()
        pattern_info = self.generate_pattern_and_measurement()
        baseline_info = self.generate_baseline(pattern_info)
        
        input_data = {
            "time": time,
            "location": location,
            "object": object_str,
            "pattern_info": pattern_info,
            "baseline_info": baseline_info
        }
        
        # Input í…ìŠ¤íŠ¸ ìƒì„±
        input_text = self.generate_input_text(input_data)
        
        # Output í…ìŠ¤íŠ¸ ìƒì„±
        output_text = self.generate_natural_output(input_data)
        
        # ë„ë©”ì¸ëª…
        domain = "ì´ìƒ ì´ë™ íŒ¨í„´ ê°ì§€"
        
        return input_text, output_text, domain
    
    def generate_dataset(self, count: int) -> List[Tuple[str, str, str]]:
        """ë°ì´í„°ì…‹ ìƒì„±"""
        dataset = []
        
        print(f"ğŸ”„ ë„ë©”ì¸10 ë°ì´í„°ì…‹ {count}ê°œ ìƒì„± ì¤‘...")
        
        for i in range(count):
            if (i + 1) % 100 == 0:
                print(f"   ì§„í–‰ë¥ : {i + 1}/{count} ({((i + 1)/count)*100:.1f}%)")
            
            data = self.generate_single_data()
            dataset.append(data)
        
        print(f"âœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {count}ê°œ")
        return dataset
    
    def save_to_csv(self, dataset: List[Tuple[str, str, str]], filepath: str):
        """CSV íŒŒì¼ ì €ì¥"""
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile, quoting=csv.QUOTE_ALL)
            writer.writerow(['Input', 'Output', 'Domain'])
            
            for input_str, output_str, domain in dataset:
                writer.writerow([input_str, output_str, domain])
        
        print(f"ğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filepath}")
    
    def validate_dataset(self, dataset: List[Tuple[str, str, str]]) -> Dict:
        """ë°ì´í„°ì…‹ ê²€ì¦"""
        # íŒ¨í„´ ìœ í˜• ë¶„í¬
        pattern_distribution = {p: 0 for p in self.movement_patterns.keys()}
        
        # ê°ì²´ ìœ í˜• ë¶„í¬
        object_distribution = {"ì‚¬ëŒ": 0, "ì°¨ëŸ‰": 0}
        
        # ì¸¡ì • ë‹¨ìœ„ ë¶„í¬
        unit_distribution = {"ê±°ë¦¬(m)": 0, "ì‹œê°„(ì´ˆ)": 0}
        
        # ê¸°ì¤€ ì„¤ì • ë¶„í¬
        baseline_distribution = {"ê¸°ì¤€ìˆìŒ": 0, "ê¸°ì¤€ì—†ìŒ": 0}
        
        # ì‹œê°„ í˜•ì‹ ë¶„í¬
        time_formats = {"HH:MM": 0, "í•œê¸€ì‹œê°„": 0}
        
        # ì¥ì†Œ í˜•ì‹ ë¶„í¬
        location_types = {"ë‹¨ìˆœì¥ì†Œ": 0, "ì¥ì†Œ+êµ¬ì—­ëª…": 0}
        
        # Input í˜•ì‹ ë¶„í¬
        input_types = {"êµ¬ì¡°í˜•": 0, "ì„¤ëª…í˜•": 0}
        
        # ë¬¸ì¥ ê¸¸ì´ ë¶„í¬
        sentence_lengths = {"2ë¬¸ì¥": 0, "3ë¬¸ì¥": 0, "4ë¬¸ì¥": 0, "ê¸°íƒ€": 0}
        
        # ìœ„í—˜ë„ ë¶„í¬
        risk_distribution = {"ìœ„í—˜ìƒí™©": 0, "ì •ìƒìƒí™©": 0, "ê¸°ì¤€ì—†ìŒìƒí™©": 0}
        
        for input_str, output_str, domain in dataset:
            # íŒ¨í„´ ìœ í˜• ì²´í¬
            for pattern in self.movement_patterns.keys():
                if pattern in input_str:
                    pattern_distribution[pattern] += 1
                    break
            
            # ê°ì²´ ìœ í˜• ì²´í¬
            if any(person in input_str for person in self.person_types):
                object_distribution["ì‚¬ëŒ"] += 1
            else:
                object_distribution["ì°¨ëŸ‰"] += 1
            
            # ì¸¡ì • ë‹¨ìœ„ ì²´í¬
            if "m" in input_str:
                unit_distribution["ê±°ë¦¬(m)"] += 1
            elif "ì´ˆ" in input_str:
                unit_distribution["ì‹œê°„(ì´ˆ)"] += 1
            
            # ê¸°ì¤€ ì„¤ì • ì²´í¬
            if any(phrase in input_str for phrase in ["ê¸°ì¤€:", "ê¸°ì¤€ "]):
                baseline_distribution["ê¸°ì¤€ìˆìŒ"] += 1
            else:
                baseline_distribution["ê¸°ì¤€ì—†ìŒ"] += 1
            
            # ì‹œê°„ í˜•ì‹ ì²´í¬
            if re.search(r'\d{2}:\d{2}', input_str):
                time_formats["HH:MM"] += 1
            else:
                time_formats["í•œê¸€ì‹œê°„"] += 1
            
            # ì¥ì†Œ í˜•ì‹ ì²´í¬
            has_complex_location = False
            for complex_loc in self.locations["complex"]:
                if complex_loc in input_str:
                    has_complex_location = True
                    break
            
            if has_complex_location:
                location_types["ì¥ì†Œ+êµ¬ì—­ëª…"] += 1
            else:
                location_types["ë‹¨ìˆœì¥ì†Œ"] += 1
            
            # Input í˜•ì‹ ì²´í¬ (ì„¤ëª…í˜• í‚¤ì›Œë“œ í™•ì¸)
            if any(keyword in input_str for keyword in ["ë³´ì˜€ìœ¼ë©°", "ë¨¸ë¬¼ë €ìŠµë‹ˆë‹¤", "ë™ì‘ì„", "ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤"]):
                input_types["ì„¤ëª…í˜•"] += 1
            else:
                input_types["êµ¬ì¡°í˜•"] += 1
            
            # ë¬¸ì¥ ê¸¸ì´ ì²´í¬ (ë§ˆì¹¨í‘œ ê¸°ì¤€)
            sentence_count = len([s for s in output_str.split('.') if s.strip()])
            
            if sentence_count == 2:
                sentence_lengths["2ë¬¸ì¥"] += 1
            elif sentence_count == 3:
                sentence_lengths["3ë¬¸ì¥"] += 1
            elif sentence_count == 4:
                sentence_lengths["4ë¬¸ì¥"] += 1
            else:
                sentence_lengths["ê¸°íƒ€"] += 1
            
            # ìœ„í—˜ë„ ì²´í¬
            if any(word in output_str for word in ["ì´ˆê³¼", "ë„˜ì–´", "ìƒíšŒ", "ì¦‰ì‹œ", "ê¸´ê¸‰"]):
                risk_distribution["ìœ„í—˜ìƒí™©"] += 1
            elif any(word in output_str for word in ["ë¶€í•©", "ì •ìƒ", "ì–‘í˜¸"]):
                risk_distribution["ì •ìƒìƒí™©"] += 1
            else:
                risk_distribution["ê¸°ì¤€ì—†ìŒìƒí™©"] += 1
        
        total_count = len(dataset)
        
        return {
            "total_count": total_count,
            "pattern_distribution": {
                p: f"{pattern_distribution[p]} ({pattern_distribution[p]/total_count*100:.1f}%)"
                for p in self.movement_patterns.keys()
            },
            "object_distribution": {
                "ì‚¬ëŒ": f"{object_distribution['ì‚¬ëŒ']} ({object_distribution['ì‚¬ëŒ']/total_count*100:.1f}%)",
                "ì°¨ëŸ‰": f"{object_distribution['ì°¨ëŸ‰']} ({object_distribution['ì°¨ëŸ‰']/total_count*100:.1f}%)"
            },
            "unit_distribution": {
                "ê±°ë¦¬(m)": f"{unit_distribution['ê±°ë¦¬(m)']} ({unit_distribution['ê±°ë¦¬(m)']/total_count*100:.1f}%)",
                "ì‹œê°„(ì´ˆ)": f"{unit_distribution['ì‹œê°„(ì´ˆ)']} ({unit_distribution['ì‹œê°„(ì´ˆ)']/total_count*100:.1f}%)"
            },
            "baseline_distribution": {
                "ê¸°ì¤€ìˆìŒ": f"{baseline_distribution['ê¸°ì¤€ìˆìŒ']} ({baseline_distribution['ê¸°ì¤€ìˆìŒ']/total_count*100:.1f}%)",
                "ê¸°ì¤€ì—†ìŒ": f"{baseline_distribution['ê¸°ì¤€ì—†ìŒ']} ({baseline_distribution['ê¸°ì¤€ì—†ìŒ']/total_count*100:.1f}%)"
            },
            "time_formats": {
                "HH:MM": f"{time_formats['HH:MM']} ({time_formats['HH:MM']/total_count*100:.1f}%)",
                "í•œê¸€ì‹œê°„": f"{time_formats['í•œê¸€ì‹œê°„']} ({time_formats['í•œê¸€ì‹œê°„']/total_count*100:.1f}%)"
            },
            "location_types": {
                "ë‹¨ìˆœì¥ì†Œ": f"{location_types['ë‹¨ìˆœì¥ì†Œ']} ({location_types['ë‹¨ìˆœì¥ì†Œ']/total_count*100:.1f}%)",
                "ì¥ì†Œ+êµ¬ì—­ëª…": f"{location_types['ì¥ì†Œ+êµ¬ì—­ëª…']} ({location_types['ì¥ì†Œ+êµ¬ì—­ëª…']/total_count*100:.1f}%)"
            },
            "input_types": {
                "êµ¬ì¡°í˜•": f"{input_types['êµ¬ì¡°í˜•']} ({input_types['êµ¬ì¡°í˜•']/total_count*100:.1f}%)",
                "ì„¤ëª…í˜•": f"{input_types['ì„¤ëª…í˜•']} ({input_types['ì„¤ëª…í˜•']/total_count*100:.1f}%)"
            },
            "sentence_lengths": {
                "2ë¬¸ì¥": f"{sentence_lengths['2ë¬¸ì¥']} ({sentence_lengths['2ë¬¸ì¥']/total_count*100:.1f}%)",
                "3ë¬¸ì¥": f"{sentence_lengths['3ë¬¸ì¥']} ({sentence_lengths['3ë¬¸ì¥']/total_count*100:.1f}%)",
                "4ë¬¸ì¥": f"{sentence_lengths['4ë¬¸ì¥']} ({sentence_lengths['4ë¬¸ì¥']/total_count*100:.1f}%)",
                "ê¸°íƒ€": f"{sentence_lengths['ê¸°íƒ€']} ({sentence_lengths['ê¸°íƒ€']/total_count*100:.1f}%)"
            },
            "risk_distribution": {
                "ìœ„í—˜ìƒí™©": f"{risk_distribution['ìœ„í—˜ìƒí™©']} ({risk_distribution['ìœ„í—˜ìƒí™©']/total_count*100:.1f}%)",
                "ì •ìƒìƒí™©": f"{risk_distribution['ì •ìƒìƒí™©']} ({risk_distribution['ì •ìƒìƒí™©']/total_count*100:.1f}%)",
                "ê¸°ì¤€ì—†ìŒìƒí™©": f"{risk_distribution['ê¸°ì¤€ì—†ìŒìƒí™©']} ({risk_distribution['ê¸°ì¤€ì—†ìŒìƒí™©']/total_count*100:.1f}%)"
            }
        }

if __name__ == "__main__":
    """
    ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
    - 1000ê°œ ë°ì´í„°ì…‹ ìƒì„±
    - CSV íŒŒì¼ ì €ì¥
    - ê²€ì¦ ê²°ê³¼ ì¶œë ¥
    """
    # ë°ì´í„°ì…‹ ìƒì„±ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    generator = Domain10AbnormalMovementGenerator()
    
    # 1000ê°œ ë°ì´í„°ì…‹ ìƒì„±
    dataset = generator.generate_dataset(5000)
    
    # ì €ì¥ ê²½ë¡œ ì„¤ì •
    output_path = os.path.join(os.path.dirname(__file__), '..', 'csv', 'domain10_dataset.csv')
    generator.save_to_csv(dataset, output_path)
    
    # ë°ì´í„°ì…‹ ê²€ì¦ ë° ê²°ê³¼ ì¶œë ¥
    validation_results = generator.validate_dataset(dataset)
    
    print(f"\nâœ… ë„ë©”ì¸10 ë°ì´í„°ì…‹ 1000ê°œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
    print("\nğŸ“Š ë°ì´í„°ì…‹ ê²€ì¦ ê²°ê³¼:")
    print(f"   ì´ ë°ì´í„° ê°œìˆ˜: {validation_results['total_count']}ê°œ")
    
    print(f"\nğŸ­ ì´ìƒ ì´ë™ íŒ¨í„´ ë¶„í¬:")
    for pattern, stats in validation_results['pattern_distribution'].items():
        print(f"   {pattern}: {stats}")
    
    print(f"\nğŸ‘¥ ê°ì²´ ìœ í˜• ë¶„í¬:")
    print(f"   ì‚¬ëŒ: {validation_results['object_distribution']['ì‚¬ëŒ']}")
    print(f"   ì°¨ëŸ‰: {validation_results['object_distribution']['ì°¨ëŸ‰']}")
    
    print(f"\nğŸ“ ì¸¡ì • ë‹¨ìœ„ ë¶„í¬:")
    print(f"   ê±°ë¦¬(m): {validation_results['unit_distribution']['ê±°ë¦¬(m)']}")
    print(f"   ì‹œê°„(ì´ˆ): {validation_results['unit_distribution']['ì‹œê°„(ì´ˆ)']}")
    
    print(f"\nğŸ“‹ ê¸°ì¤€ ì„¤ì • ë¶„í¬:")
    print(f"   ê¸°ì¤€ìˆìŒ: {validation_results['baseline_distribution']['ê¸°ì¤€ìˆìŒ']}")
    print(f"   ê¸°ì¤€ì—†ìŒ: {validation_results['baseline_distribution']['ê¸°ì¤€ì—†ìŒ']}")
    
    print(f"\nâ° ì‹œê°„ í˜•ì‹ ë¶„í¬:")
    print(f"   HH:MM í˜•ì‹: {validation_results['time_formats']['HH:MM']}")
    print(f"   í•œê¸€ ì‹œê°„: {validation_results['time_formats']['í•œê¸€ì‹œê°„']}")
    
    print(f"\nğŸ¢ ì¥ì†Œ í˜•ì‹ ë¶„í¬:")
    print(f"   ë‹¨ìˆœì¥ì†Œ: {validation_results['location_types']['ë‹¨ìˆœì¥ì†Œ']}")
    print(f"   ì¥ì†Œ+êµ¬ì—­ëª…: {validation_results['location_types']['ì¥ì†Œ+êµ¬ì—­ëª…']}")
    
    print(f"\nğŸ“ Input í˜•ì‹ ë¶„í¬:")
    print(f"   êµ¬ì¡°í˜•: {validation_results['input_types']['êµ¬ì¡°í˜•']}")
    print(f"   ì„¤ëª…í˜•: {validation_results['input_types']['ì„¤ëª…í˜•']}")
    
    print(f"\nğŸ“„ ë¬¸ì¥ ê¸¸ì´ ë¶„í¬:")
    print(f"   2ë¬¸ì¥: {validation_results['sentence_lengths']['2ë¬¸ì¥']}")
    print(f"   3ë¬¸ì¥: {validation_results['sentence_lengths']['3ë¬¸ì¥']}")
    print(f"   4ë¬¸ì¥: {validation_results['sentence_lengths']['4ë¬¸ì¥']}")
    print(f"   ê¸°íƒ€: {validation_results['sentence_lengths']['ê¸°íƒ€']}")
    
    print(f"\nâš ï¸ ìœ„í—˜ë„ ë¶„í¬:")
    print(f"   ìœ„í—˜ìƒí™©: {validation_results['risk_distribution']['ìœ„í—˜ìƒí™©']}")
    print(f"   ì •ìƒìƒí™©: {validation_results['risk_distribution']['ì •ìƒìƒí™©']}")
    print(f"   ê¸°ì¤€ì—†ìŒìƒí™©: {validation_results['risk_distribution']['ê¸°ì¤€ì—†ìŒìƒí™©']}") 